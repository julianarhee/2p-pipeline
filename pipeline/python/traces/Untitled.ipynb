{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except():\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        # this is used for debugging purposes only. allows to reload classes\n",
    "        # when changed\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "\n",
    "\n",
    "import pylab as pl\n",
    "from functools import partial\n",
    "import tifffile as tf\n",
    "import multiprocessing as mp\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import optparse\n",
    "import sys\n",
    "\n",
    "\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "\n",
    "\n",
    "from caiman.source_extraction.cnmf.initialization import downscale as cmdownscale\n",
    "\n",
    "\n",
    "\n",
    "def extract_options(options):\n",
    "\n",
    "    parser = optparse.OptionParser()\n",
    "\n",
    "    # PATH opts:\n",
    "    parser.add_option('-D', '--root', action='store', dest='rootdir', default='/n/coxfs01/2p-data', help='data root dir (root project dir containing all animalids) [default: /n/coxfs01/2pdata]')\n",
    "    parser.add_option('-i', '--animalid', action='store', dest='animalid', default='', help='Animal ID')\n",
    "    parser.add_option('-S', '--session', action='store', dest='session', default='', help='session dir (format: YYYMMDD_ANIMALID')\n",
    "    parser.add_option('-A', '--acq', action='store', dest='fov', default='FOV1_zoom2p0x', help=\"acquisition folder (ex: 'FOV1_zoom2p0x') [default: FOV1_zoom2p0x]\")\n",
    "    parser.add_option('-E', '--exp', action='store', dest='experiment', default='', help=\"Name of experiment (stimulus type), e.g., rfs\")\n",
    "    parser.add_option('-t', '--traceid', action='store', dest='traceid', default='traces001', help=\"Traceid from which to get seeded rois (default: traces001)\")\n",
    "\n",
    "\n",
    "    parser.add_option('-n', '--nproc', action=\"store\",\n",
    "                      dest=\"n_processes\", default=2, help=\"N processes [default: 1]\")\n",
    "    parser.add_option('-d', '--downsample', action=\"store\",\n",
    "                      dest=\"ds_factor\", default=5, help=\"Downsample factor (int, default: 5)\")\n",
    "\n",
    "    parser.add_option('--destdir', action=\"store\",\n",
    "                      dest=\"destdir\", default='/n/scratchlfs/cox_lab/julianarhee/downsampled', help=\"output dir for movie files [default: /n/scratchlfs/cox_lab/julianarhee/downsampled]\")\n",
    "    parser.add_option('--plot', action='store_true', dest='plot_rois', default=False, help=\"set to plot results of each roi's analysis\")\n",
    "    parser.add_option('--processed', action='store_false', dest='use_raw', default=True, help=\"set to downsample on non-raw source\")\n",
    "\n",
    "    parser.add_option('--new', action='store_true', dest='create_new', default=False, help=\"Set to downsample and motion correct anew\")\n",
    "    parser.add_option('--prefix', action='store', dest='prefix', default='Yr', help=\"Prefix for sourced memmap/mc files (default: Yr)\")\n",
    "\n",
    "\n",
    "    (options, args) = parser.parse_args(options)\n",
    "\n",
    "    return options\n",
    "\n",
    "def caiman_params(fnames):\n",
    "    # dataset dependent parameters\n",
    "    fr = 44.65                             # imaging rate in frames per second\n",
    "    decay_time = 0.4                    # length of a typical transient in seconds\n",
    "\n",
    "    # motion correction parameters\n",
    "    strides = (48, 48)          # start a new patch for pw-rigid motion correction every x pixels\n",
    "    overlaps = (24, 24)         # overlap between pathes (size of patch strides+overlaps)\n",
    "    max_shifts = (6,6)          # maximum allowed rigid shifts (in pixels)\n",
    "    max_deviation_rigid = 3     # maximum shifts deviation allowed for patch with respect to rigid shifts\n",
    "    pw_rigid = False             # flag for performing non-rigid motion correction\n",
    "\n",
    "    # parameters for source extraction and deconvolution\n",
    "    p = 2                       # order of the autoregressive system\n",
    "    gnb = 2                     # number of global background components\n",
    "    merge_thr = 0.85            # merging threshold, max correlation allowed\n",
    "    rf = 25                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "    stride_cnmf = 12             # amount of overlap between the patches in pixels\n",
    "    K = 8                      # number of components per patch\n",
    "    gSig = [2, 2]               # expected half size of neurons in pixels\n",
    "    method_init = 'greedy_roi'  # initialization method (if analyzing dendritic data using 'sparse_nmf')\n",
    "    ssub = 1                    # spatial subsampling during initialization\n",
    "    tsub = 1                    # temporal subsampling during intialization\n",
    "\n",
    "    # parameters for component evaluation\n",
    "    min_SNR = 2.0               # signal to noise ratio for accepting a component\n",
    "    rval_thr = 0.85              # space correlation threshold for accepting a component\n",
    "    cnn_thr = 0.99              # threshold for CNN based classifier\n",
    "    cnn_lowest = 0.1 # neurons with cnn probability lower than this value are rejected\n",
    "\n",
    "    opts_dict = {'fnames': fnames,\n",
    "                'fr': fr,\n",
    "                'decay_time': decay_time,\n",
    "                'strides': strides,\n",
    "                'overlaps': overlaps,\n",
    "                'max_shifts': max_shifts,\n",
    "                'max_deviation_rigid': max_deviation_rigid,\n",
    "                'pw_rigid': pw_rigid,\n",
    "                'p': 1,\n",
    "                'nb': gnb,\n",
    "                'rf': rf,\n",
    "                'K': K, \n",
    "                'stride': stride_cnmf,\n",
    "                'method_init': method_init,\n",
    "                'rolling_sum': True,\n",
    "                'only_init': True,\n",
    "                'ssub': ssub,\n",
    "                'tsub': tsub,\n",
    "                'merge_thr': merge_thr, \n",
    "                'min_SNR': min_SNR,\n",
    "                'rval_thr': rval_thr,\n",
    "                'use_cnn': True,\n",
    "                'min_cnn_thr': cnn_thr,\n",
    "                'cnn_lowest': cnn_lowest}\n",
    "\n",
    "    opts = params.CNMFParams(params_dict=opts_dict)\n",
    "\n",
    "    return opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_mc_results(results_dir, prefix='Yr'):\n",
    "    np.savez(os.path.join(results_dir, 'mc_rigid.npz'),\n",
    "            mc=mc,\n",
    "            fname=mc.fname, max_shifts=mc.max_shifts, min_mov=mc.min_mov,\n",
    "            border_nan=mc.border_nan,\n",
    "            fname_tot_rig=mc.fname_tot_rig,\n",
    "            total_template_rig=mc.total_template_rig,\n",
    "            templates_rig=mc.templates_rig,\n",
    "            shifts_rig=mc.shifts_rig,\n",
    "            mmap_file=mc.mmap_file,\n",
    "            border_to_0=mc.border_to_0)\n",
    "    print(\"--- saved MC results: %s\" % os.path.join(results_dir, '%s_mc-rigid.npz' % prefix))\n",
    "\n",
    "    \n",
    "def load_mc_results(results_dir, prefix='Yr'):\n",
    "    try:\n",
    "        mc_results = np.load(os.path.join(results_dir, '%s_mc-rigid.npz' % prefix))\n",
    "        mc = mc_results[mc] \n",
    "#            fname=mc.fname, max_shifts=mc.max_shifts, min_mov=mc.min_mov,\n",
    "#            border_nan=mc.border_nan,\n",
    "#            fname_tot_rig=mc.fname_tot_rig,\n",
    "#            total_template_rig=mc.total_template_rig,\n",
    "#            templates_rig=mc.templates_rig,\n",
    "#            shifts_rig=mc.shifts_rig,\n",
    "#            mmap_file=mc.mmap_file,\n",
    "#            border_to_0=mc.border_to_0)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "    return mc \n",
    "\n",
    "def get_file_paths(results_dir, prefix='Yr'):\n",
    "    try:\n",
    "        mparams_fpath = os.path.join(results_dir, '%s_memmap-params.json' % prefix)\n",
    "        print(\"Loading memmap params...\")\n",
    "        with open(mparams_fpath, 'r') as f:\n",
    "            mparams = json.load(f)\n",
    "        fnames = mparams['fnames']\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            dpath = glob.glob(os.path.join(results_dir, 'memmap', '*%s*.npz' % prefix))[0]#) [0]) \n",
    "            minfo = np.load(dpath)\n",
    "            fnames = sorted(list(minfo['mmap_fnames']))\n",
    "        except Exception as e:\n",
    "            print(\"unable to load file names.\")\n",
    "            return None\n",
    "    \n",
    "    return fnames #fnames = mparams['fnames']\n",
    "\n",
    "def get_full_memmap_path(results_dir, prefix='Yr'):\n",
    "    print(\"Getting full mmap path for prefix: %s\" % prefix)\n",
    "    fname_new = glob.glob(os.path.join(results_dir, 'memmap', '*%s*_d*_.mmap' % prefix))[0]\n",
    "    prefix = os.path.splitext(os.path.split(fname_new)[-1])[0].split('_d1_')[0]\n",
    "    print(\"CORRECTED PREFIX: %s\" % prefix)\n",
    "    return fname_new, prefix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_roiid_from_traceid(animalid, session, fov, run_type=None, traceid='traces001', rootdir='/n/coxfs01/2p-data'):\n",
    "    \n",
    "    if run_type is not None:\n",
    "        if int(session) < 20190511 and run_type == 'gratings':\n",
    "            a_traceid_dict = glob.glob(os.path.join(rootdir, animalid, session, fov, '*run*', 'traces', 'traceids*.json'))[0]\n",
    "        else:\n",
    "            a_traceid_dict = glob.glob(os.path.join(rootdir, animalid, session, fov, '*%s*' % run_type, 'traces', 'traceids*.json'))[0]\n",
    "    else:\n",
    "        a_traceid_dict = glob.glob(os.path.join(rootdir, animalid, session, fov, '*run*', 'traces', 'traceids*.json'))[0]\n",
    "    with open(a_traceid_dict, 'r') as f:\n",
    "        tracedict = json.load(f)\n",
    "    \n",
    "    tid = tracedict[traceid]\n",
    "    roiid = tid['PARAMS']['roi_id']\n",
    "    \n",
    "    return roiid\n",
    "\n",
    "\n",
    "def load_roi_masks(animalid, session, fov, rois=None, rootdir='/n/coxfs01/2p-data'):\n",
    "    masks=None; zimg=None;\n",
    "    mask_fpath = glob.glob(os.path.join(rootdir, animalid, session, 'ROIs', '%s*' % rois, 'masks.hdf5'))[0]\n",
    "    try:\n",
    "        mfile = h5py.File(mask_fpath, 'r')\n",
    "\n",
    "        # Load and reshape masks\n",
    "        fkey = list(mfile.keys())[0]\n",
    "        masks = mfile[fkey]['masks']['Slice01'][:] #.T\n",
    "        #print(masks.shape)\n",
    "        #mfile[mfile.keys()[0]].keys()\n",
    "\n",
    "        zimg = mfile[fkey]['zproj_img']['Slice01'][:] #.T\n",
    "        zimg.shape\n",
    "    except Exception as e:\n",
    "        print(\"error loading masks\")\n",
    "    finally:\n",
    "        mfile.close()\n",
    "        \n",
    "    return masks, zimg\n",
    "\n",
    "def reshape_and_binarize_masks(masks):\n",
    "    # Binarze and reshape:\n",
    "    nrois, d1, d2 = masks.shape\n",
    "    Ain = np.reshape(masks, (nrois, d1*d2))\n",
    "    Ain[Ain>0] = 1\n",
    "    Ain = Ain.astype(bool).T \n",
    "    \n",
    "    return Ain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['-i', 'JC084', '-S', '20190525', '-A', 'FOV1_zoom2p0x', '-E', 'gratings', \n",
    "          '--prefix=JC084-20190525-FOV1_zoom2p0x-gratings-downsample-5', '-n', 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = extract_options(options) \n",
    "rootdir = opts.rootdir #'/n/coxfs01/2p-data'\n",
    "animalid = opts.animalid #'JC084'\n",
    "session = opts.session #'20190525' #'20190505_JC083'\n",
    "fov = opts.fov\n",
    "experiment = opts.experiment\n",
    "ds_factor = int(opts.ds_factor)\n",
    "destdir = opts.destdir\n",
    "use_raw = opts.use_raw\n",
    "n_processes = int(opts.n_processes) \n",
    "create_new = opts.create_new\n",
    "prefix = opts.prefix\n",
    "traceid=opts.traceid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting seeds...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load manual ROIs and format\n",
    "print(\"Getting seeds...\")\n",
    "roiid = get_roiid_from_traceid(animalid, session, fov, run_type=experiment, traceid=traceid)\n",
    "masks, zimg = load_roi_masks(animalid, session, fov, rois=roiid)\n",
    "Ain = reshape_and_binarize_masks(masks)\n",
    "Ain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
