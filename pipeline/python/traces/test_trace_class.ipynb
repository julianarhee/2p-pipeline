{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import h5py\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "import optparse\n",
    "import pprint\n",
    "import traceback\n",
    "import time\n",
    "import skimage\n",
    "import shutil\n",
    "import fissa\n",
    "import cv2\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "import tifffile as tf\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import cPickle as pkl\n",
    "from skimage import img_as_uint\n",
    "from pipeline.python.utils import natural_keys, hash_file_read_only, load_sparse_mat, print_elapsed_time, hash_file, replace_root, uint16_to_RGB\n",
    "from pipeline.python.set_trace_params import post_tid_cleanup\n",
    "from pipeline.python.rois.utils import get_info_from_tiff_dir\n",
    "from pipeline.python.traces.utils import get_frame_info, get_metric_set\n",
    "from pipeline.python.paradigm import align_acquisition_events as acq\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_RID(session_dir, roi_id):\n",
    "\n",
    "    roi_dir = os.path.join(session_dir, 'ROIs')\n",
    "    roidict_path = glob.glob(os.path.join(roi_dir, 'rids_*.json'))[0]\n",
    "    with open(roidict_path, 'r') as f:\n",
    "        roidict = json.load(f)\n",
    "    RID = roidict[roi_id]\n",
    "\n",
    "    return RID\n",
    "\n",
    "    \n",
    "def load_TID(run_dir, trace_id, auto=False):\n",
    "    run = os.path.split(run_dir)[-1]\n",
    "    trace_dir = os.path.join(run_dir, 'traces')\n",
    "    tmp_tid_dir = os.path.join(trace_dir, 'tmp_tids')\n",
    "    tracedict_path = os.path.join(trace_dir, 'traceids_%s.json' % run)\n",
    "    try:\n",
    "        print \"Loading params for TRACE SET, id %s\" % trace_id\n",
    "        with open(tracedict_path, 'r') as f:\n",
    "            tracedict = json.load(f)\n",
    "        TID = tracedict[trace_id]\n",
    "        pp.pprint(TID)\n",
    "    except Exception as e:\n",
    "        print \"No TRACE SET entry exists for specified id: %s\" % trace_id\n",
    "        print \"TRACE DIR:\", tracedict_path\n",
    "        print tracedict.keys()\n",
    "        try:\n",
    "            print \"Checking tmp trace-id dir...\"\n",
    "            if auto is False:\n",
    "                while True:\n",
    "                    tmpfns = [t for t in os.listdir(tmp_tid_dir) if t.endswith('json')]\n",
    "                    for tidx, tidfn in enumerate(tmpfns):\n",
    "                        print tidx, tidfn\n",
    "                    userchoice = raw_input(\"Select IDX of found tmp trace-id to view: \")\n",
    "                    with open(os.path.join(tmp_tid_dir, tmpfns[int(userchoice)]), 'r') as f:\n",
    "                        tmpTID = json.load(f)\n",
    "                    print \"Showing tid: %s, %s\" % (tmpTID['trace_id'], tmpTID['trace_hash'])\n",
    "                    pp.pprint(tmpTID)\n",
    "                    userconfirm = raw_input('Press <Y> to use this trace ID, or <q> to abort: ')\n",
    "                    if userconfirm == 'Y':\n",
    "                        TID = tmpTID\n",
    "                        break\n",
    "                    elif userconfirm == 'q':\n",
    "                        break\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            print \"---------------------------------------------------------------\"\n",
    "            print \"No tmp trace-ids found either... ABORTING with error:\"\n",
    "            print e\n",
    "            print \"---------------------------------------------------------------\"\n",
    "\n",
    "    return TID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "def masks_to_normed_array(masks):\n",
    "    '''\n",
    "    Assumes masks.shape = (d1, d2, nrois)\n",
    "\n",
    "    Returns:\n",
    "        maskarray of shape (d, nrois), where d = d1*d2\n",
    "        values are normalized by size of mask\n",
    "    '''\n",
    "    d1, d2 = masks[:,:,0].shape\n",
    "    d = d1*d2\n",
    "\n",
    "    nrois = masks.shape[-1]\n",
    "\n",
    "    masks_arr = np.empty((d, nrois))\n",
    "    for r in range(nrois):\n",
    "        masks_arr[:, r] = np.reshape(masks[:,:,r], (d,), order='C') /  len(np.nonzero(masks[:,:,r])[0])\n",
    "\n",
    "    return masks_arr\n",
    "\n",
    "\n",
    "#%%\n",
    "def get_gradient(im) :\n",
    "    # Calculate the x and y gradients using Sobel operator\n",
    "    grad_x = cv2.Sobel(im,cv2.CV_32F,1,0,ksize=3)\n",
    "    grad_y = cv2.Sobel(im,cv2.CV_32F,0,1,ksize=3)\n",
    "\n",
    "    # Combine the two gradients\n",
    "    grad = cv2.addWeighted(np.absolute(grad_x), 0.5, np.absolute(grad_y), 0.5, 0)\n",
    "    return grad\n",
    "\n",
    "#%%\n",
    "#def uint16_to_RGB(img):\n",
    "#    im = img.astype(np.float64)/img.max()\n",
    "#    im = 255 * im\n",
    "#    im = im.astype(np.uint8)\n",
    "#    rgb = cv2.cvtColor(im, cv2.COLOR_GRAY2BGR)\n",
    "#    return rgb\n",
    "\n",
    "def plot_warped_rois(ref, sample, masks, masks_aligned, out_fpath='/tmp/aligned_rois.png'):\n",
    "    refRGB = uint16_to_RGB(ref)\n",
    "    imRGB = uint16_to_RGB(sample)\n",
    "    wimRGB = uint16_to_RGB(sample)\n",
    "    nrois = masks.shape[-1]\n",
    "\n",
    "    fig = pl.figure(figsize=(15,5))\n",
    "    fig.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1, hspace=0.1, wspace=0.1)\n",
    "    ax1 = fig.add_subplot(1,3,1); pl.imshow(refRGB, cmap='gray'); pl.title('ref rois'); pl.axis('off')\n",
    "    ax2 = fig.add_subplot(1,3,2); pl.imshow(imRGB, cmap='gray'); pl.title('sample, orig rois'); pl.axis('off')\n",
    "    ax3 = fig.add_subplot(1,3,3); pl.imshow(imRGB, cmap='gray'); pl.title('sample, warped rois'); pl.axis('off')\n",
    "    for ridx in range(nrois):\n",
    "        #roinum = ridx + 1\n",
    "        orig = masks[:,:,ridx].copy().astype('uint8')\n",
    "        # Draw contour for ORIG rois on reference:\n",
    "        ret,thresh = cv2.threshold(orig,.5,255,0)\n",
    "        orig2,contours,hierarchy = cv2.findContours(thresh, 1, 2)\n",
    "        cv2.drawContours(refRGB, contours, 0, (0,255,0), 1)\n",
    "        ax1.imshow(refRGB)\n",
    "        # Draw orig ROIs on sample:\n",
    "        cv2.drawContours(imRGB, contours, 0, (0,255,0), 1)\n",
    "        ax2.imshow(imRGB)\n",
    "        # Draw orig ROIs + warped ROIs on sample (i.e., ref rois warped to match sample)\n",
    "        alig = masks_aligned[:,:,ridx].copy().astype('uint8')\n",
    "        ret,thresh = cv2.threshold(alig,.5,255,0)\n",
    "        aligC,contours2,hierarchy = cv2.findContours(thresh, 1, 2)\n",
    "        cv2.drawContours(wimRGB, contours, 0, (0,255,0), 1)\n",
    "        cv2.drawContours(wimRGB, contours2, 0, (255,0,0), 1)\n",
    "        ax3.imshow(wimRGB)\n",
    "\n",
    "    #figname = 'aligned_rois.png'\n",
    "    pl.savefig(out_fpath)\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_neuropil_masks(masks, niterations=10):\n",
    "    # Create kernel for dilating ROIs:\n",
    "    kernel = np.ones((3,3),masks.dtype)\n",
    "\n",
    "    nrois = masks.shape[-1]\n",
    "    np_masks = np.empty(masks.shape, dtype=masks.dtype)\n",
    "\n",
    "    for ridx in range(nrois):\n",
    "        rmask = masks[:,:,ridx]\n",
    "        if niterations==20:\n",
    "            gap_iterations = 8\n",
    "        else:\n",
    "            gap_iterations = 4\n",
    "        gap = cv2.dilate(rmask, kernel, iterations=gap_iterations)\n",
    "        dilated = cv2.dilate(rmask, kernel, iterations=niterations)\n",
    "\n",
    "        # Subtract to get annulus region:\n",
    "        annulus = (dilated - gap)\n",
    "\n",
    "        # Get full mask image to subtract overlaps:\n",
    "        allmasks = np.sum(masks, axis=-1)\n",
    "        summed = annulus + allmasks\n",
    "        summed[summed>1] = 0\n",
    "\n",
    "        # Add annulus back in to make neuropil area = 2, everythign else = 1:\n",
    "        summed += annulus\n",
    "        neuropil = summed - allmasks\n",
    "        np_masks[:,:,ridx] = neuropil.astype('bool')\n",
    "\n",
    "    return np_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_options(options):\n",
    "    choices_npmethod = ('fissa', 'annulus')\n",
    "    default_npmethod = 'annulus'\n",
    "\n",
    "    choices_tracetype = ('raw', 'raw_fissa', 'denoised_nmf', 'np_corrected_fissa', 'neuropil_fissa', 'np_subtracted', 'neuropil')\n",
    "    default_tracetype = 'raw'\n",
    "\n",
    "    parser = optparse.OptionParser()\n",
    "\n",
    "    # PATH opts:\n",
    "    parser.add_option('-D', '--root', action='store', dest='rootdir', default='/nas/volume1/2photon/data', help='data root dir (root project dir containing all animalids) [default: /nas/volume1/2photon/data, /n/coxfs01/2pdata if --slurm]')\n",
    "    parser.add_option('-i', '--animalid', action='store', dest='animalid', default='', help='Animal ID')\n",
    "    parser.add_option('-S', '--session', action='store', dest='session', default='', help='session dir (format: YYYMMDD_ANIMALID')\n",
    "    parser.add_option('-A', '--acq', action='store', dest='acquisition', default='FOV1', help=\"acquisition folder (ex: 'FOV1_zoom3x') [default: FOV1]\")\n",
    "    parser.add_option('-R', '--run', action='store', dest='run', default='', help=\"name of run dir containing tiffs to be processed (ex: gratings_phasemod_run1)\")\n",
    "    parser.add_option('--default', action='store_true', dest='default', default='store_false', help=\"Use all DEFAULT params, for params not specified by user (no interactive)\")\n",
    "    parser.add_option('--slurm', action='store_true', dest='slurm', default=False, help=\"set if running as SLURM job on Odyssey\")\n",
    "    parser.add_option('-t', '--trace-id', action='store', dest='trace_id', default='', help=\"Trace ID for current trace set (created with set_trace_params.py, e.g., traces001, traces020, etc.)\")\n",
    "\n",
    "    parser.add_option('--new', action=\"store_true\",\n",
    "                      dest=\"create_new\", default=False, help=\"Set flag to create new output files (/paradigm/parsed_frames.hdf5, roi_trials.hdf5\")\n",
    "    parser.add_option('--append', action=\"store_true\",\n",
    "                      dest=\"append_trace_type\", default=False, help=\"Set flag to append non-default trace type to trace structs (e.g., neuropil correction).\")\n",
    "\n",
    "    parser.add_option('--np', type='choice', choices=choices_npmethod, action='store', dest='np_method', default=default_npmethod, help=\"Method for neuropil correction. Valid choices: %s [default: %s]\" % (choices_npmethod, default_npmethod))\n",
    "\n",
    "    parser.add_option('-N', '--ncores', action=\"store\",\n",
    "                      dest=\"ncores\", default=2, help=\"[np-fissa]: N cores to use for FISSA prep and separation [default: 2, 4. If slurm, 1]\")\n",
    "\n",
    "    # Neuropil options:\n",
    "    parser.add_option('-a', '--halo', action=\"store\",\n",
    "                      dest=\"np_niterations\", default=10, help=\"[np-subtract]:  N iterations for ROI dilation when creating annulus for neuropil [default: 10]\")\n",
    "    parser.add_option('-c', '--cfactor', action=\"store\",\n",
    "                      dest=\"np_correction_factor\", default=0.5, help=\"[np-subtract]: Correction factor for neuropil subtraction [default: 0.5]\")\n",
    "    parser.add_option('--neuropil', action=\"store_true\",\n",
    "                      dest=\"do_neuropil_correction\", default=False, help=\"Set flag to extract neuropil.\")\n",
    "    parser.add_option('--warp', action=\"store_true\",\n",
    "                      dest=\"save_warp_images\", default=False, help=\"Set flag to save output plots of warped ROIs (manual warp only).\")\n",
    "\n",
    "    (options, args) = parser.parse_args(options)\n",
    "\n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "def update_dict(d, u):\n",
    "    for k, v in u.iteritems():\n",
    "        if isinstance(v, collections.Mapping):\n",
    "            d[k] = update(d.get(k, {}), v)\n",
    "        else:\n",
    "            d[k] = v\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_rois(zproj_img, maskarray, save_dir='/tmp', figname='roi_masks.png', \n",
    "                      plot_neuropil=False, np_maskarray=None, np_niterations=None):\n",
    "\n",
    "    d1, d2 = zproj_img.shape\n",
    "    nrois = maskarray.shape[1] \n",
    "\n",
    "    #print \"--- Mask array: %i ROIs on %s, %s\" % (nrois, curr_file, curr_slice)\n",
    "    print \"--- Mask array: %i ROIs saved to %s\" % (nrois, figname)\n",
    "    fig = pl.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    p2, p98 = np.percentile(zproj_img, (2, 99.98))\n",
    "    avgimg = skimage.exposure.rescale_intensity(zproj_img, in_range=(p2, p98)) #avg *= (1.0/avg.max())\n",
    "    ax.imshow(avgimg, cmap='gray')\n",
    "\n",
    "    npmasks_r = None\n",
    "    if plot_neuropil is True:\n",
    "        assert np_maskarray is not None, \"No NP masks provided!\"\n",
    "        npmasks_r = np.reshape(np_maskarray, (d1, d2, nrois))\n",
    "        \n",
    "    masks_r = np.reshape(maskarray, (d1, d2, nrois))\n",
    "    \n",
    "    for ridx in range(nrois):\n",
    "        masktmp = masks_r[:, :, ridx]\n",
    "        msk = masktmp.copy()\n",
    "        msk[msk==0] = np.nan\n",
    "\n",
    "        if np.isnan(masktmp).all():\n",
    "            ax.text(1, 1, '%i - no mask' % int(ridx+1), fontsize=8, weight='light', color='r')\n",
    "        else:\n",
    "            ax.imshow(msk, interpolation='None', alpha=0.5, cmap=pl.cm.Greens_r, vmin=0, vmax=1.0)\n",
    "            [ys, xs] = np.where(masktmp>0)\n",
    "            ax.text(xs[int(round(len(xs)/4))], ys[int(round(len(ys)/4))], str(ridx+1), fontsize=8, weight='light', color='w')\n",
    "\n",
    "        if npmasks_r is not None and plot_neuropil is True:\n",
    "            masktmp = npmasks_r[:, :, ridx]\n",
    "            msk = masktmp.copy()\n",
    "            msk[msk==0] = np.nan\n",
    "            ax.imshow(msk, interpolation='None', alpha=0.2, cmap=pl.cm.Blues_r)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    pl.savefig(os.path.join(save_dir, figname))\n",
    "    pl.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoiMask class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RoiMasks():\n",
    "    def __init__(self, mask_fpath):\n",
    "        try:\n",
    "            maskfile = h5py.File(mask_fpath, 'r')\n",
    "        except Exception as e:\n",
    "            print \"Unable to read specified mask file at: %s\" % mask_fpath\n",
    "        \n",
    "        self.source_file = mask_fpath\n",
    "        self.is_3D = maskfile.attrs['is_3D'] in ['True']\n",
    "        self.roi_id = maskfile.attrs['roi_id'] \n",
    "        self.roi_hash = maskfile.attrs['roi_hash'] \n",
    "        self.roi_type = maskfile.attrs['roi_type'] \n",
    "        self.zproj_type = maskfile.attrs['zproj']\n",
    "        \n",
    "        # Check if masks have a single .tif reference:\n",
    "        if len(maskfile.keys()) == 1:\n",
    "            self.ref_file = maskfile.keys()[0]\n",
    "            self.single_reference = True\n",
    "\n",
    "        # Get signal channel for ROI source:\n",
    "        self.signal_channel = os.path.split(os.path.split(maskfile[maskfile.keys()[0]]['masks'].attrs['source'])[0])[-1]\n",
    "        \n",
    "        # Get slices for which there are ROIs in this set:\n",
    "        self.roi_slices = sorted([str(s) for s in maskfile[maskfile.keys()[0]]['masks'].keys()], key=natural_keys)\n",
    "\n",
    "        # Identify tiff source for ROIs:\n",
    "        rootdir = mask_fpath.split('/%s' % maskfile.attrs['animal'])[0]\n",
    "        roidict_path = glob.glob(os.path.join(rootdir, maskfile.attrs['animal'], maskfile.attrs['session'], 'ROIs', 'rids_*.json'))[0]\n",
    "        with open(roidict_path, 'r') as f: roidict = json.load(f);\n",
    "        self.roi_tiff_src = roidict[self.roi_id]['SRC']\n",
    "\n",
    "        # Get masks from ROI SOURCE: -- assuming is_slice_format = True (i.e., ROIs are savd by SLICE, not grouped altogether)\n",
    "#        self.masks = dict((curr_slice, maskfile[self.ref_file]['masks'][curr_slice][:].T.copy()) \\\n",
    "#                                               for curr_slice in maskfile[self.ref_file]['masks'].keys())\n",
    "        self.source_mask = maskfile[self.ref_file]['masks']['Slice01'][:].T        \n",
    "        self.masks = {}\n",
    "\n",
    "    def get_reference_image(self, zproj_type='mean'):\n",
    "        \n",
    "        self.ref_img_path = glob.glob('%s_%s_deinterleaved/%s/%s/*.tif' % (self.roi_tiff_src, zproj_type, self.signal_channel, self.ref_file))[0]\n",
    "        self.reference_img = tf.imread(self.ref_img_path)\n",
    "\n",
    "        \n",
    "    def get_masks(self, target_paths, nprocs=4, save_warp_images=True, output_dir='/tmp'):\n",
    "\n",
    "        print \"Getting masks for %i .tif files.\" % len(target_paths)\n",
    "        if save_warp_images:\n",
    "            print \"Saving warped ROI mask images to: %s\" % output_dir\n",
    "    \n",
    "        t_eval_mp = time.time()\n",
    "        def worker(target_paths_list, out_q, save_warp_images, output_dir):\n",
    "            \"\"\"\n",
    "            Worker function is invoked in a process. 'target_paths_list' is a list of\n",
    "            files for which to warp reference masks.\n",
    "            \"\"\"\n",
    "            print \"Starting!\"\n",
    "            warps = {}\n",
    "            for target_fpath in target_paths_list:\n",
    "                fname = os.path.splitext(os.path.split(target_fpath)[-1])[0]\n",
    "                curr_file = str(re.search('File(\\d{3})', target_fpath).group(0))\n",
    "                warps[curr_file] = {'maskarray': None, 'np_maskarray': None}\n",
    "                if target_fpath == self.ref_img_path:\n",
    "                    # Don't need to do anything but normalize array:\n",
    "                    warps[curr_file]['maskarray'] = masks_to_normed_array(self.masks)\n",
    "                else:\n",
    "                    print \"... Warping %s to ref.\" % target_fpath\n",
    "                    target_img = tf.imread(target_fpath)\n",
    "                    masks_aligned = self.warp_mask(target_img)\n",
    "                    warps[curr_file]['maskarray'] = masks_to_normed_array(masks_aligned)\n",
    "                    if save_warp_images:\n",
    "                        warp_img_path = os.path.join(output_dir, 'warped_rois_r%s_to_%s.png' % (self.ref_file, fname))\n",
    "                        plot_warped_rois(self.reference_img, target_img, self.source_mask, masks_aligned, \n",
    "                                             out_fpath=warp_img_path)\n",
    "            out_q.put(warps)\n",
    "    \n",
    "        # Each process gets \"chunksize' filenames and a queue to put his out-dict into:\n",
    "        out_q = mp.Queue()\n",
    "        chunksize = int(math.ceil(len(target_paths) / float(nprocs)))\n",
    "        procs = []\n",
    "        for i in range(nprocs):\n",
    "            p = mp.Process(target=worker,\n",
    "                           args=(target_paths[chunksize * i:chunksize * (i + 1)],\n",
    "                                        out_q,\n",
    "                                        save_warp_images,\n",
    "                                        output_dir))\n",
    "            procs.append(p)\n",
    "            p.start()\n",
    "    \n",
    "        # Collect all results into single results dict. We should know how many dicts to expect:\n",
    "        resultdict = {}\n",
    "        for i in range(nprocs):\n",
    "            resultdict.update(out_q.get())\n",
    "    \n",
    "        # Wait for all worker processes to finish\n",
    "        for p in procs:\n",
    "            print \"Finished:\", p\n",
    "            p.join()\n",
    "        print_elapsed_time(t_eval_mp)\n",
    "    \n",
    "        self.masks = resultdict\n",
    "\n",
    "    def warp_mask(self, target_img, warp_mode=cv2.MOTION_HOMOGRAPHY):\n",
    "\n",
    "        height, width = self.reference_img.shape\n",
    "    \n",
    "        # Define motion model\n",
    "        # Set the warp matrix to identity.\n",
    "        if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
    "            warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "        else:\n",
    "            warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "    \n",
    "        # Set the stopping criteria for the algorithm.\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 5000,  1e-6)\n",
    "    \n",
    "        # Warp REFERENCE image into sample:\n",
    "        sample = target_img.copy()\n",
    "        (cc, warp_matrix) = cv2.findTransformECC (get_gradient(sample), get_gradient(self.reference_img), warp_matrix, warp_mode, criteria)\n",
    "    \n",
    "        #% Warp masks with warp transform:\n",
    "        masks_aligned = np.zeros(self.source_mask.shape, dtype=self.source_mask.dtype)\n",
    "        nrois = self.source_mask.shape[-1]\n",
    "        for r in xrange(0, nrois):\n",
    "            masks_aligned[:,:,r] = cv2.warpPerspective (self.source_mask[:,:,r], warp_matrix, (width, height), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "    \n",
    "        return masks_aligned\n",
    "\n",
    "\n",
    "    def create_neuropil_masks(self, niter):\n",
    "        for curr_file in self.masks.keys():\n",
    "            nrois = self.masks[curr_file]['maskarray'].shape[-1]\n",
    "            d1, d2 = self.reference_img.shape\n",
    "            m_array = np.reshape(self.masks[curr_file]['maskarray'], (d1, d2, nrois))\n",
    "            np_masks = create_neuropil_masks(m_array, niterations=niter)\n",
    "            self.masks[curr_file]['np_maskarray'] = masks_to_normed_array(np_masks)\n",
    "        self.np_niterations = niter\n",
    "            \n",
    "    def plot_rois(self, plot_neuropil=False, output_dir='/tmp'):\n",
    "        curr_slice = 'Slice01'\n",
    "        for curr_file in self.masks.keys():\n",
    "            if plot_neuropil is True:\n",
    "                figname = 'rois_%s_%s_%s_np_niter%i.png' % (curr_file, curr_slice, self.roi_id, self.np_niterations)\n",
    "            else:\n",
    "                figname = 'rois_%s_%s_%s.png' % (curr_file, curr_slice, self.roi_id)\n",
    "\n",
    "            curr_maskarray = self.masks[curr_file]['maskarray']\n",
    "            curr_np_maskarray = self.masks[curr_file]['np_maskarray'] if plot_neuropil else None\n",
    "            np_iters = self.np_niterations if plot_neuropil else None\n",
    "            plot_rois(self.reference_img, curr_maskarray, \n",
    "                          save_dir=output_dir, figname=figname, \n",
    "                          plot_neuropil=plot_neuropil,\n",
    "                          np_maskarray=curr_np_maskarray,\n",
    "                          np_niterations=np_iters)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traces class defintiion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Traces():\n",
    "    \n",
    "    def __init__(self, optsE):\n",
    "        self.rootdir = optsE.rootdir\n",
    "        self.animalid = optsE.animalid\n",
    "        self.session = optsE.session\n",
    "        self.acquisition = optsE.acquisition\n",
    "        self.run = optsE.run\n",
    "        self.trace_id = optsE.trace_id\n",
    "        \n",
    "        # Load meta data for current trace extraction:\n",
    "        run_dir = os.path.join(self.rootdir, self.animalid, self.session, self.acquisition, self.run)\n",
    "        print run_dir, self.trace_id\n",
    "        session_dir = os.path.join(self.rootdir, self.animalid, self.session)\n",
    "        self.TID = load_TID(run_dir, self.trace_id)\n",
    "        self.meta = {'SI': get_frame_info(run_dir),\n",
    "                     'RID': load_RID(session_dir, self.TID['PARAMS']['roi_id'])}\n",
    "        if self.rootdir not in self.meta['RID']['DST']:\n",
    "            self.meta['RID']['DST'] = replace_root(self.meta['RID']['DST'], self.rootdir, self.animalid, self.session)\n",
    "            \n",
    "        self.masks = None\n",
    "        \n",
    "        self.nonnegative = '_offset' in self.TID['SRC'] \n",
    "        self.do_neuropil_correction = optsE.do_neuropil_correction\n",
    "        self.np_method = optsE.np_method\n",
    "        self.np_niterations = optsE.np_niterations\n",
    "        self.np_correction_factor = optsE.np_correction_factor\n",
    "                    \n",
    "    def get_sources(self):\n",
    "        self.get_tiff_source()\n",
    "        self.get_mask_source()\n",
    "\n",
    "\n",
    "    def get_masks(self, new_soma=False, new_neuropil=False, nprocs=4, save_warp_images=False):\n",
    "        self.soma_masks(nprocs=nprocs, save_warp_images=save_warp_images, create_new=new_soma)\n",
    "        self.neuropil_masks(np_method=self.np_method, nprocs=nprocs, create_new=new_neuropil)\n",
    "        \n",
    "    def plot_rois(self, plot_neuropil=False):            \n",
    "        mask_figdir = os.path.join(self.TID['DST'], 'figures', 'masks')\n",
    "        if not os.path.exists(mask_figdir): os.makedirs(mask_figdir);\n",
    "        self.masks.plot_rois(plot_neuropil=plot_neuropil, output_dir=mask_figdir)\n",
    "\n",
    "        \n",
    "    def get_tiff_source(self):\n",
    "        # Run tiff pre-processing, if nonnegative specified:\n",
    "        if self.nonnegative and len(glob.glob(os.path.join(self.TID['SRC'], '*.tif')))==0: #os.path.exists(self.TID['tiff_dir']):\n",
    "            print \"Making tif files psuedo unsigned with offset and uint16 conversion...\"\n",
    "            orig_tiff_dir = self.TID['tiff_dir'].split('_offset')[0]\n",
    "            self.TID['tiff_dir'] = add_offset_convert_uint16(orig_tiff_dir)\n",
    "            \n",
    "        # Get list of files in current trace set:\n",
    "        excluded_tiffs = self.TID['PARAMS']['excluded_tiffs']\n",
    "        ntiffs = len(glob.glob(os.path.join(self.TID['SRC'], '*.tif')))\n",
    "        self.filenames = sorted(['File%03d' % int(i+1) for i in range(ntiffs) if 'File%03d' % int(i+1) not in excluded_tiffs], key=natural_keys)\n",
    "\n",
    "\n",
    "    def get_mask_source(self):\n",
    "        # Create mask object:\n",
    "        mask_fpath = os.path.join(self.meta['RID']['DST'], 'masks.hdf5')\n",
    "        self.masks = RoiMasks(mask_fpath)\n",
    "        if self.rootdir not in self.masks.roi_tiff_src:\n",
    "            self.masks.roi_tiff_src = replace_root(self.masks.roi_tiff_src, self.rootdir, self.animalid, self.session)\n",
    "\n",
    "        # Determine whether the ROI source is the same as the TIFF source:\n",
    "        if self.rootdir not in self.masks.roi_tiff_src: \n",
    "            self.masks.roi_tiff_src = replace_root(self.masks.roi_tiff_src, self.rootdir, self.animalid, self.session)\n",
    "        if self.rootdir not in self.TID['SRC']:\n",
    "            self.TID['SRC'] = replace_root(self.TID['SRC'], self.rootdir, self.animalid, self.session)\n",
    "            self.TID['DST'] = replace_root(self.TID['DST'], self.rootdir, self.animalid, self.session)\n",
    "\n",
    "        # Get reference image for masks:\n",
    "        self.masks.get_reference_image()\n",
    "            \n",
    "        # Always use the mean image to do the ROI warping:\n",
    "        if self.masks.roi_tiff_src == self.TID['SRC']:\n",
    "            print \"Extracting traces from ROI source\"\n",
    "            self.masks.matched_sources = True\n",
    "            self.masks.zproj_source_dir = '%s_mean_deinterleaved/%s' % (self.masks.roi_tiff_src, self.masks.signal_channel)\n",
    "            self.masks.zproj_ref = self.masks.ref_file\n",
    "        else:\n",
    "            print \"Extracting traces from ALT run roi src\"\n",
    "            self.masks.matched_sources = False\n",
    "            # Identify which file was used as reference, assuming tiffs were preprocessed and motion-corrected:\n",
    "            if 'mcorrected' in self.TID['SRC']:\n",
    "                # Use processing info to get motion-corrected reference file:\n",
    "                processed_dir = os.path.split(self.TID['SRC'].split('/mcorrected')[0])[1]\n",
    "                process_id = os.path.split(processed_dir)[-1]\n",
    "                pid_fpath = glob.glob(os.path.join(self.rootdir, self.animalid, self.session, self.acquisition, self.run, 'processed', 'pids_*.json'))[0]\n",
    "                with open(pid_fpath, 'r') as f: pdict = json.load(f)\n",
    "                self.masks.zproj_ref = 'File%03d' % int(pdict[process_id.split('_')[0]]['PARAMS']['motion']['ref_file'])\n",
    "            # Get corresponding zproj source dir:\n",
    "            self.masks.zproj_source_dir = '%s_mean_deinterleaved/%s' % (self.TID['SRC'], self.masks.signal_channel)\n",
    "\n",
    "        \n",
    "    def soma_masks(self, nprocs=4, save_warp_images=False, create_new=False):\n",
    "        mfile = None\n",
    "        if not create_new:\n",
    "            try:\n",
    "                warped_mask_path = glob.glob(os.path.join(self.TID['DST'], 'MASKS.hdf5'))[0]\n",
    "                mfile = h5py.File(warped_mask_path, 'r')\n",
    "                file_masks = dict((curr_file, {'maskarray': np.array(mfile[curr_file]['maskarray'][:])}) \n",
    "                                            for curr_file in mfile.keys())\n",
    "                self.masks.masks = update_dict(self.masks.masks, file_masks)\n",
    "            except Exception as e:\n",
    "                traceback.print_exc()\n",
    "                print \"Unable to load existing mask array file. Creating new!\"\n",
    "                create_new = True\n",
    "            finally:\n",
    "                if mfile is not None:\n",
    "                    mfile.close()\n",
    "                \n",
    "        if create_new:\n",
    "            target_paths = glob.glob(os.path.join('%s_mean_deinterleaved/%s' % (self.TID['SRC'], \n",
    "                                                                                self.masks.signal_channel), \n",
    "                                                                                  'File*', '*.tif'))\n",
    "            # Check if alrady have plotted masks, if not, create new:\n",
    "            warps_figdir = os.path.join(self.TID['DST'], 'figures', 'warp_results')\n",
    "            if not os.path.exists(warps_figdir): os.makedirs(warps_figdir);\n",
    "            if len(glob.glob(os.path.join(warps_figdir, '*.png'))) != len(target_paths)-1:\n",
    "                save_warp_images = True\n",
    "\n",
    "            self.masks.get_masks(target_paths, nprocs=nprocs, save_warp_images=save_warp_images, output_dir=warps_figdir)\n",
    "            self.save_warped_masks('maskarray')\n",
    "            \n",
    "            \n",
    "    def neuropil_masks(self, np_method='annulus', nprocs=4, create_new=False):\n",
    "        \n",
    "        if np_method == 'annulus':\n",
    "            mfile=None\n",
    "            if not create_new:\n",
    "                try:\n",
    "                    print \"Loading annulus for neuropil.\"\n",
    "                    warped_mask_path = glob.glob(os.path.join(self.TID['DST'], 'MASKS.hdf5'))[0]\n",
    "                    mfile = h5py.File(warped_mask_path, 'r')\n",
    "\n",
    "                    file_masks = dict((curr_file, {'np_maskarray': np.array(mfile[curr_file]['np_maskarray'][:])}) \n",
    "                                                for curr_file in mfile.keys())\n",
    "                    self.masks.masks = update_dict(self.masks.masks, file_masks)\n",
    "                    self.masks.np_niterations = self.np_niterations\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print traceback.print_exc()\n",
    "                    print \"Unable to load existing NP masks. Creating new!\"\n",
    "                    create_new = True\n",
    "                finally:\n",
    "                    if mfile is not None:\n",
    "                        mfile.close()\n",
    "                    \n",
    "            if create_new:\n",
    "                self.masks.create_neuropil_masks(niter=self.np_niterations)\n",
    "                self.save_warped_masks('np_maskarray')\n",
    "            \n",
    "    def save_warped_masks(self, mask_key):\n",
    "        warp_mask_path = os.path.join(self.TID['DST'], 'MASKS.hdf5')\n",
    "        print \"Saving intermediary warped masks to: %s\" % warp_mask_path\n",
    "        mfile = None\n",
    "        try:\n",
    "            if not os.path.exists(warp_mask_path):\n",
    "                mfile = h5py.File(warp_mask_path, 'w')\n",
    "            else:\n",
    "                mfile = h5py.File(warp_mask_path, 'r+')\n",
    "\n",
    "            assert mask_key in self.masks.masks['File001'].keys(), \"Specified key %s not found!\" % mask_key\n",
    "\n",
    "            for curr_file in self.masks.masks.keys():\n",
    "                if curr_file not in mfile.keys():\n",
    "                    filegrp = mfile.create_group(curr_file)\n",
    "                else:\n",
    "                    filegrp = mfile[curr_file]\n",
    "                    \n",
    "                if mask_key not in filegrp.keys():\n",
    "                    #print \"Creating: %s\" % mask_key\n",
    "                    m = filegrp.create_dataset(mask_key, \n",
    "                                           self.masks.masks[curr_file][mask_key].shape, \n",
    "                                           self.masks.masks[curr_file][mask_key].dtype)\n",
    "                else:\n",
    "                    #print \"Overwriting: %s\" % mask_key\n",
    "                    m = filegrp[mask_key]\n",
    "                m[...] = self.masks.masks[curr_file][mask_key]\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "        finally:\n",
    "            if mfile is not None:\n",
    "                mfile.close()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST trace class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/coxfs01/2p-data/CE077/20180523/FOV1_zoom1x/gratings_run1 traces004\n",
      "Loading params for TRACE SET, id traces004\n",
      "{   u'DST': u'/mnt/odyssey/CE077/20180523/FOV1_zoom1x/gratings_run1/traces/traces004_4bf731',\n",
      "    u'PARAMS': {   u'excluded_tiffs': [],\n",
      "                   u'hashid': u'ebc661',\n",
      "                   u'nonnegative': False,\n",
      "                   u'offset_uint16': False,\n",
      "                   u'rid_hash': u'adfc97',\n",
      "                   u'roi_id': u'rois001',\n",
      "                   u'roi_type': u'manual2D_circle',\n",
      "                   u'signal_channel': 1,\n",
      "                   u'tiff_source': u'/mnt/odyssey/CE077/20180523/FOV1_zoom1x/gratings_run1/processed/processed001_cb3497/mcorrected_a0def0',\n",
      "                   u'uint16': False},\n",
      "    u'SRC': u'/mnt/odyssey/CE077/20180523/FOV1_zoom1x/gratings_run1/processed/processed001_cb3497/mcorrected_a0def0',\n",
      "    u'trace_hash': u'4bf731',\n",
      "    u'trace_id': u'traces004',\n",
      "    u'version': u'0.1.0'}\n",
      "ORIG ROOT: /n/coxfs01/2p-data/CE077/20180523/ROIs/rois001_adfc97\n",
      "NEW ROOT: /n/coxfs01/2p-data/CE077/20180523/ROIs/rois001_adfc97\n"
     ]
    }
   ],
   "source": [
    "options = ['-D', '/n/coxfs01/2p-data', '-i', 'CE077', '-S', '20180523', '-A', 'FOV1_zoom1x', \n",
    "           '-R', 'gratings_run1', '-t', 'traces004', '--neuropil', '-c', 0.7, '-a', 10]\n",
    "optsE = extract_options(options)\n",
    "T = Traces(optsE)\n",
    "\n",
    "\n",
    "T.get_sources()\n",
    "\n",
    "T.get_masks(new_soma=False, new_neuropil=False, nprocs=4, save_warp_images=False)\n",
    "\n",
    "\n",
    "T.plot_rois(plot_neuropil=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tables as tb\n",
    "\n",
    "tb.file._open_files.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warp_mask_path = os.path.join(T.TID['DST'], 'MASKS.hdf5')\n",
    "mfile = h5py.File(warp_mask_path, 'a')\n",
    "for curr_file in T.masks.masks.keys():\n",
    "    if curr_file not in mfile.keys():\n",
    "        filegrp = mfile.create_group(curr_file)\n",
    "    else:\n",
    "        filegrp = mfile[curr_file]\n",
    "        \n",
    "    m = filegrp.create_dataset('maskarray', T.masks.masks[curr_file]['maskarray'].shape, \n",
    "                        T.masks.masks[curr_file]['maskarray'].dtype)\n",
    "    \n",
    "    m[...] = T.masks.masks[curr_file]['maskarray']\n",
    "    \n",
    "mfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
