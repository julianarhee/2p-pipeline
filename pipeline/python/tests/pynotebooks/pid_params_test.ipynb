{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "import pkg_resources\n",
    "import pandas as pd\n",
    "import optparse\n",
    "import sys\n",
    "import hashlib\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "# GENERAL METHODS:\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]\n",
    "\n",
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    this function will convert bytes to MB.... GB... etc\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "\n",
    "def get_file_size(file_path):\n",
    "    \"\"\"\n",
    "    this function will return the file size\n",
    "    \"\"\"\n",
    "    if os.path.isfile(file_path):\n",
    "        file_info = os.stat(file_path)\n",
    "        return convert_bytes(file_info.st_size)\n",
    "\n",
    "def set_motion_params(correct_motion=False,\n",
    "                 ref_channel=0,\n",
    "                 ref_file=0,\n",
    "                 method=None,\n",
    "                 algorithm=None\n",
    "                ):\n",
    "\n",
    "    mc_methods = ['Acquisition2P', 'NoRMCorre']\n",
    "    mc_algos = dict((mc, []) for mc in mc_methods)\n",
    "    mc_algos = {'Acquisition2P': ['@withinFile_withinFrame_lucasKanade', '@lucasKanade_plus_nonrigid'],\n",
    "                'NoRMCorre': ['rigid', 'nonrigid']}\n",
    "\n",
    "    if correct_motion is True:\n",
    "        if method is None:\n",
    "            while True:\n",
    "                print \"No MC method specified. Use default [Acquisition2P]?\"\n",
    "                mc_choice = raw_input('Enter <Y> to use default, or <o> to see options:')\n",
    "                if mc_choice == 'Y':\n",
    "                    print \"Using default.\"\n",
    "                    method = 'Acquisition2P'\n",
    "                    break\n",
    "                elif mc_choice == 'o':\n",
    "                    for mcid, mcname in enumerate(mc_methods):\n",
    "                        print mcid, mcname\n",
    "                    mc_select = input('Enter IDX of motion-correction method to use:')\n",
    "                    method = mc_methods[mc_select]\n",
    "                    break\n",
    "        if algorithm is None or (algorithm not in mc_algos[method]):\n",
    "            print \"No MC algorithm specified... Here are the options:\"\n",
    "            for algonum, algoname in enumerate(mc_algos[method]):\n",
    "                print algonum, algoname\n",
    "            algo_choice = input('Enter IDX of mc algorithm to use:')\n",
    "            algorithm = mc_algos[method][algo_choice] \n",
    "    else:\n",
    "        ref_channel = 0\n",
    "        ref_file = 0\n",
    "        method = None\n",
    "        algorithm = None\n",
    "        \n",
    "    motion_params = dict()\n",
    "    motion_params['correct_motion'] = correct_motion\n",
    "    motion_params['method'] = method\n",
    "    motion_params['algorithm'] = algorithm\n",
    "    motion_params['ref_channel'] = ref_channel\n",
    "    motion_params['ref_file'] = ref_file\n",
    "    \n",
    "    return motion_params\n",
    "\n",
    "def set_preprocessing_params(correct_flyback=False,\n",
    "                  nflyback_frames=0,\n",
    "                  correct_bidir=False,\n",
    "                  split_channels=False\n",
    "                 ):\n",
    "    \n",
    "    preprocess_params = dict()\n",
    "    if correct_flyback is False:\n",
    "        nflyback_frames = 0\n",
    "    \n",
    "    preprocess_params['correct_flyback'] = correct_flyback\n",
    "    preprocess_params['nflyback_frames'] = nflyback_frames\n",
    "    preprocess_params['correct_bidir'] = correct_bidir\n",
    "    preprocess_params['split_channels'] = split_channels\n",
    "   \n",
    "    return preprocess_params\n",
    "\n",
    "\n",
    "def set_params(rootdir='', animalid='', session='', acquisition='', run='', tiffsource=None,\n",
    "               correct_bidir=False, correct_flyback=False, nflyback_frames=None,\n",
    "               split_channels=False, correct_motion=False, ref_file=1, ref_channel=1,\n",
    "               mc_method=None, mc_algorithm=None):\n",
    "    \n",
    "    '''\n",
    "    Create a dictionary of PARAMS used for processing TIFFs.\n",
    "    PARAMS = {\n",
    "        'source' : {\n",
    "            'rootdir' (str)\n",
    "                Root base of all data\n",
    "            'animalid' : str\n",
    "                Animal name (letters and numbers only, e.g., CE052)\n",
    "            'session' (str)\n",
    "                Session name (standard format: YYYYMMDD_<animalid>, e.g., 20171026_CE052)\n",
    "            'acquisition': str\n",
    "                Name of subdir in session directory for tiffs of a given FOV (e.g., FOV1_zoom3x')\n",
    "            'run' (str)\n",
    "                Name of experimental run (e.g., 'gratings_run1'). Child dir is 'raw' (acquired tiffs, read-only).\n",
    "            'tiffsource' (str)\n",
    "                Name of folder containing tiffs to be processed\n",
    "                Full file-tree ex, <rootdir>/<animalid>/<session>/<acquisition>/<run>/raw\n",
    "                }\n",
    "        'motion' : {\n",
    "            'correct_motion' (bool)\n",
    "                True/False for whether to correct motion or not.\n",
    "            'method' (str)\n",
    "                Package to use for motion-correction (default: Acquisition2P)\n",
    "                Options: Acquisition2P, NoRMCorre\n",
    "            'algorithm' (str)\n",
    "                Algorithm to use for motion-correction (default: '@withinFile_withinFrame_lucasKanade')\n",
    "                Options:\n",
    "                    Acquisition2P: '@withinFile_withinFrame_lucasKanade', '@lucasKanade_plus_nonrigid'\n",
    "                    NoRMCorre: 'rigid', 'nonrigid'\n",
    "            'ref_channel' (str)\n",
    "                Reference channel to use for motion-correction (default: 1)\n",
    "            'ref_file' (str)\n",
    "                Reference file to use for motion-correction (default: 1)\n",
    "            }\n",
    "        'preprocessing' : {\n",
    "            'correct_flyback' (bool)\n",
    "                Whether to correct for bad flyback settings by removing extra frames from top of stack.\n",
    "                Assumes stack acquisition starts from top (default: False)\n",
    "            'nflyback_frames' (int)\n",
    "                Number of extra frames to remove from the stack to correct flyback error (default: 1)\n",
    "            'correct_bidir' (bool)\n",
    "                Whether to correct scan phase if acquired with bidirectional scanning (default: False)\n",
    "            'split_channels' (bool)\n",
    "                Whether to split channels for extra large files (default: False)\n",
    "                Will automatically check file size and set this to True if doing bidi- and motion-correction,\n",
    "                since Matlab limit is 4GB.\n",
    "                }\n",
    "        'hashid' (str)\n",
    "            Generated hash using the above key-value pairs, specific to PARAMS.\n",
    "            Note: full PID dict includes extra house-keeping info that gets its own hash id.       \n",
    "    }\n",
    "    '''\n",
    "    \n",
    "    PARAMS = dict()\n",
    "    PARAMS['source'] = dict()\n",
    "\n",
    "    acquisition_dir = os.path.join(rootdir, animalid, session, acquisition)\n",
    "    \n",
    "    # Check tiffs to see if should split-channels for Matlab-based MC:\n",
    "    if correct_motion is True or correct_bidir is True:\n",
    "        rawdir_name = [r for r in os.listdir(os.path.join(acquisition_dir, run)) if 'raw' in r][0]\n",
    "        rawtiff_dir = os.path.join(acquisition_dir, run, rawdir_name)\n",
    "        tiffs = [t for t in os.listdir(rawtiff_dir) if t.endswith('tif')]\n",
    "        file_sizes = [get_file_size(os.path.join(rawtiff_dir, t)) for t in tiffs]\n",
    "        gb_files = [f for f in file_sizes if 'GB' in f]\n",
    "        toobig = [g for g in gb_files if float(g.split('GB')[0]) > 4.0]\n",
    "        if len(toobig) > 0:\n",
    "            split_channels = True\n",
    "        \n",
    "    # ----------------------------------------------------------\n",
    "    # Get source params:\n",
    "    # ----------------------------------------------------------\n",
    "    PARAMS['source']['rootdir'] = rootdir\n",
    "    PARAMS['source']['animalid'] = animalid\n",
    "    PARAMS['source']['session'] = session\n",
    "    PARAMS['source']['acquisition'] = acquisition\n",
    "    PARAMS['source']['run'] = run\n",
    "\n",
    "    if not os.path.exists(os.path.join(acquisition_dir, run, 'processed')): \n",
    "        os.makedirs(os.path.join(acquisition_dir, run, 'processed'))\n",
    "\n",
    "    processed_dirs = sorted([p for p in os.listdir(os.path.join(acquisition_dir, run, 'processed'))\n",
    "                              if 'processed' in p], key=natural_keys)\n",
    " \n",
    "    if tiffsource is None or len(tiffsource) == 0:\n",
    "        while True:\n",
    "            print \"TIFF SOURCE was not specified.\"\n",
    "            tiffsource_type = raw_input('Enter <P> if source is processed, <R> if raw: ')\n",
    "            if tiffsource_type == 'R':\n",
    "                tiffsource = 'raw'\n",
    "                break\n",
    "            elif tiffsource_type =='P':\n",
    "                print \"Selected PROCESSED source.\"\n",
    "                pp.pprint(processed_dirs)\n",
    "                if process_dict is None or (len(process_dict.keys()) == 0 and len(processed_dirs) == 0):\n",
    "                    tiffsource = 'processed%03d' % int(len(processed_dirs) + 1)\n",
    "                else:\n",
    "                    candidate_sources = sorted(process_dict.keys(), key=natural_keys)\n",
    "                    for pdix, pdir in enumerate(candidate_sources):\n",
    "                        print pdix, pdir\n",
    "                    tiffsource_idx = input('Select IDX of processed dir to use as source: ')\n",
    "                    if tiffsource_idx < len(candidate_sources):\n",
    "                        tiffsource = candidate_sources[int(tiffsource_idx)]\n",
    "                confirm_selection = raw_input('Selected %s. Press <Y> to confirm.' % tiffsource)\n",
    "                if confirm_selection == 'Y':\n",
    "                    break\n",
    "                    \n",
    "    PARAMS['source']['tiffsource'] = tiffsource\n",
    "    \n",
    "    # ----------------------------------------------------------\n",
    "    # Get preprocessing opts:\n",
    "    # ----------------------------------------------------------\n",
    "    PARAMS['preprocessing'] = set_preprocessing_params(correct_flyback=correct_flyback,\n",
    "                             nflyback_frames=nflyback_frames,\n",
    "                             correct_bidir=correct_bidir,\n",
    "                             split_channels=split_channels)\n",
    "    \n",
    "    # ------------------------------------------\n",
    "    # Check user-provided MC params:\n",
    "    # ------------------------------------------\n",
    "    print correct_motion\n",
    "    PARAMS['motion'] = mcparams = set_motion_params(correct_motion=correct_motion,\n",
    "                            ref_channel=ref_channel,\n",
    "                            ref_file=ref_file,\n",
    "                            method=mc_method,\n",
    "                            algorithm=mc_algorithm)\n",
    "\n",
    "    PARAMS['hashid'] = hashlib.sha1(json.dumps(PARAMS, sort_keys=True)).hexdigest()\n",
    "    \n",
    "    return PARAMS\n",
    "\n",
    "\n",
    "def initialize_pid(PARAMS, acquisition_dir, run, auto=False):\n",
    "    \n",
    "    print \"************************\"\n",
    "    print \"Initialize PID.\"\n",
    "    print \"************************\"\n",
    "    process_id, is_new_pid, create_pid_file = get_process_id(PARAMS, acquisition_dir, run, auto=auto)\n",
    "\n",
    "    pid = dict()\n",
    "    version = pkg_resources.get_distribution('pipeline').version\n",
    "    \n",
    "    pid['version'] = version \n",
    "    pid['process_id'] = process_id\n",
    "    pid['PARAMS'] = PARAMS\n",
    "    pid['SRC'] = os.path.join(acquisition_dir, run, PARAMS['source']['tiffsource']) #source_dir\n",
    "    pid['DST'] = os.path.join(acquisition_dir, run, 'processed', process_id)\n",
    "    \n",
    "    correct_flyback = pid['PARAMS']['preprocessing']['correct_flyback']\n",
    "    correct_bidir = pid['PARAMS']['preprocessing']['correct_bidir']\n",
    "    correct_motion = pid['PARAMS']['motion']['correct_motion']\n",
    "    \n",
    "    # Set source/dest dirs for Preprocessing tiffs:\n",
    "    pid['PARAMS']['preprocessing']['sourcedir'] = pid['SRC']\n",
    "    pid['PARAMS']['preprocessing']['destdir'] = None\n",
    "    if correct_flyback is True:\n",
    "        pid['PARAMS']['preprocessing']['destdir'] = os.path.join(pid['DST'], 'raw')\n",
    "    if correct_bidir is True:\n",
    "        pid['PARAMS']['preprocessing']['sourcedir'] = os.path.join(pid['DST'], 'raw')\n",
    "        pid['PARAMS']['preprocessing']['destdir'] = os.path.join(pid['DST'], 'bidi')\n",
    "       \n",
    "    # Set source/dest dirs for Motion-Correction:\n",
    "    pid['PARAMS']['motion']['sourcedir'] =  pid['PARAMS']['preprocessing']['destdir']\n",
    "    pid['PARAMS']['motion']['destdir'] = None\n",
    "    if correct_motion is True:\n",
    "        if pid['PARAMS']['motion']['sourcedir'] is None:\n",
    "            pid['PARAMS']['motion']['sourcedir'] = pid['SRC']\n",
    "        pid['PARAMS']['motion']['destdir'] = os.path.join(pid['DST'], 'mcorrected')\n",
    "\n",
    "    # TODO:  Generate hash for full PID dict\n",
    "    tmp_hashid = hashlib.sha1(json.dumps(pid, sort_keys=True)).hexdigest()\n",
    "    pid['tmp_hashid'] = tmp_hashid[0:6]\n",
    "    \n",
    "    return pid\n",
    "\n",
    "def load_processdict(acquisition_dir, run):\n",
    "    processdict = None\n",
    "    processdict_filepath = os.path.join(acquisition_dir, run, 'processed', 'pid_info_%s.json' % run)\n",
    "    \n",
    "    # Load analysis \"processdict\" file:\n",
    "    if os.path.exists(processdict_filepath):\n",
    "        print \"exists!\"\n",
    "        with open(processdict_filepath, 'r') as f:\n",
    "            processdict = json.load(f)\n",
    "            \n",
    "    return processdict\n",
    "\n",
    "def get_process_id(PARAMS, acquisition_dir, run, auto=False):\n",
    "    \n",
    "    process_id = None\n",
    "    \n",
    "    print \"********************************\"\n",
    "    print \"Checking previous PROCESS IDs...\"\n",
    "    print \"********************************\"\n",
    "    \n",
    "    # Load previously created PIDs:\n",
    "    processdict = load_processdict(acquisition_dir, run)\n",
    "    \n",
    "    #Check current PARAMS against existing PId params by hashid:\n",
    "    if processdict is None or len(processdict.keys()) == 0:\n",
    "        processdict = dict()\n",
    "        existing_pids = []\n",
    "        is_new_pid = True\n",
    "        print \"No existing PIDs found.\"\n",
    "        create_pid_file = True\n",
    "    else:\n",
    "        create_pid_file = False\n",
    "        existing_pids = sorted([str(k) for k in processdict.keys()], key=natural_keys)\n",
    "        matching_pids = sorted([pid for pid in existing_pids if processdict[pid]['PARAMS']['hashid'] == PARAMS['hashid']], key=natural_keys)\n",
    "        is_new_pid = False\n",
    "        if len(matching_pids) > 0:    \n",
    "            print \"Found match\"\n",
    "            while True:\n",
    "                print \"WARNING **************************************\"\n",
    "                print \"Current param config matches existing PID:\"\n",
    "                for pidx, pid in enumerate(matching_pids):\n",
    "                    print \"******************************************\"\n",
    "                    print pidx, pid\n",
    "                    pp.pprint(processdict[pid])\n",
    "                if auto is True:\n",
    "                    check_pidx = ''\n",
    "                else:\n",
    "                    check_pidx = raw_input('Enter IDX of pid to re-use, or hit <ENTER> to create new: ')\n",
    "                if len(check_pidx) == 0:\n",
    "                    is_new_pid = True\n",
    "                    break\n",
    "                else:\n",
    "                    confirm_reuse = raw_input('Re-use PID %s? Press <Y> to confirm, any key to try again:' % existing_pids[int(check_pidx)])\n",
    "                    if confirm_reuse == 'Y':\n",
    "                        is_new_pid = False\n",
    "                    break\n",
    "        else:\n",
    "            is_new_pid = True\n",
    "\n",
    "\n",
    "    if is_new_pid is True:\n",
    "        # Create new PID by incrementing num of process dirs found:\n",
    "        process_id = 'processed%03d' % int(len(existing_pids)+1)\n",
    "        print \"Creating NEW pid: %s\" % process_id\n",
    "    else:\n",
    "        # Re-using an existing PID:\n",
    "        process_id = existing_pids[int(check_pidx)]\n",
    "        print \"Reusing existing pid: %s\" % process_id\n",
    " \n",
    "    return process_id, is_new_pid, create_pid_file\n",
    "\n",
    "\n",
    "def get_default_pid(rootdir='', animalid='', session='', acquisition='', run='',\n",
    "                    correct_flyback=None, nflyback_frames=0):\n",
    "    \n",
    "    acquisition_dir = os.path.join(rootdir, animalid, session, acquisition)\n",
    "    \n",
    "    DEFPARAMS = set_params(rootdir=rootdir, animalid=animalid, session=session,\n",
    "                         acquisition=acquisition, run=run, tiffsource='raw',\n",
    "                         correct_motion=False, correct_bidir=False,\n",
    "                         correct_flyback=correct_flyback, nflyback_frames=nflyback_frames)\n",
    "    \n",
    "    # Generate new process_id based on input params:\n",
    "    pid = initialize_pid(DEFPARAMS, acquisition_dir, run)\n",
    "    \n",
    "    # UPDATE RECORDS:\n",
    "    update_records(pid, acquisition_dir, run)\n",
    "    \n",
    "    # STORE TMP FILE OF CURRENT PARAMS:\n",
    "    tmp_pid_fn = 'tmp_pid_%s.json' % pid['hashid'][0:6]\n",
    "    with open(os.path.join(acquisition_dir, run, 'processed', tmp_pid_fn), 'w') as f:\n",
    "        json.dump(pid, f, indent=4, sort_keys=True)\n",
    "        \n",
    "    return pid\n",
    "\n",
    "def update_records(pid, acquisition_dir, run):\n",
    "\n",
    "    print \"************************\"\n",
    "    print \"Updating JSONS...\"\n",
    "    print \"************************\"\n",
    "\n",
    "    processdict_filepath = os.path.join(acquisition_dir, run, 'processed', 'pid_info_%s.json' % run)\n",
    "    if os.path.exists(processdict_filepath):\n",
    "        with open(processdict_filepath, 'r') as f:\n",
    "            processdict = json.load(f)\n",
    "    else:\n",
    "        processdict = dict()\n",
    "\n",
    "    process_id = pid['process_id'] \n",
    "    processdict[process_id] = pid\n",
    "\n",
    "    #% Update Process Info DICT:\n",
    "    with open(processdict_filepath, 'w') as f:\n",
    "        json.dump(processdict, f, sort_keys=True, indent=4)\n",
    "\n",
    "    print \"Process Info UPDATED.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set OPTPARSE params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rootdir = options.rootdir\n",
    "# animalid = options.animalid\n",
    "# session = options.session\n",
    "# acquisition = options.acquisition\n",
    "# run = options.run\n",
    "\n",
    "# tiffsource = options.tiffsource\n",
    "\n",
    "# # PREPROCESSING params:\n",
    "# correct_bidir = options.bidi\n",
    "# correct_flyback = options.flyback\n",
    "# nflyback_frames = options.nflyback_frames\n",
    "\n",
    "# # MOTION params:\n",
    "# correct_motion = options.mc\n",
    "# mc_method = options.mc_method\n",
    "# mc_algorithm = options.algorithm\n",
    "# ref_file = options.ref_file\n",
    "# ref_channel = options.ref_channel\n",
    "\n",
    "rootdir = '/nas/volume1/2photon/data' #options.rootdir\n",
    "animalid = 'CE059' #options.animalid\n",
    "session = '20171009_CE059' #options.session\n",
    "acquisition = 'FOV1_zoom3x' #options.acquisition\n",
    "run = 'gratings_run1' #options.run\n",
    "\n",
    "tiffsource = 'raw' #options.tiffsource\n",
    "\n",
    "# PREPROCESSING params:\n",
    "correct_bidir = True #options.bidi\n",
    "correct_flyback = True #options.flyback\n",
    "nflyback_frames = 0 #options.nflyback_frames\n",
    "\n",
    "# MOTION params:\n",
    "correct_motion = True #options.mc\n",
    "mc_method = None #options.mc_method\n",
    "mc_algorithm = None #options.algorithm\n",
    "ref_file = 0 #options.ref_file\n",
    "ref_channel = 0 #options.ref_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "No MC method specified. Use default [Acquisition2P]?\n",
      "Enter <Y> to use default, or <o> to see options:Y\n",
      "Using default.\n",
      "No MC algorithm specified... Here are the options:\n",
      "0 @withinFile_withinFrame_lucasKanade\n",
      "1 @lucasKanade_plus_nonrigid\n",
      "Enter IDX of mc algorithm to use:0\n"
     ]
    }
   ],
   "source": [
    "    # Create config of PARAMS:\n",
    "    PARAMS = set_params(rootdir=rootdir, animalid=animalid, session=session,\n",
    "                            acquisition=acquisition, run=run, tiffsource=tiffsource,\n",
    "                            correct_bidir=correct_bidir, correct_flyback=correct_flyback, nflyback_frames=nflyback_frames,\n",
    "                            correct_motion=correct_motion, ref_file=ref_file, ref_channel=ref_channel, \n",
    "                            mc_method=mc_method, mc_algorithm=mc_algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      "Initialize PID.\n",
      "************************\n",
      "********************************\n",
      "Checking previous PROCESS IDs...\n",
      "********************************\n",
      "exists!\n",
      "Creating NEW pid: processed002\n",
      "{   'DST': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002',\n",
      "    'PARAMS': {   'hashid': '06e4b48390af95a507582e5866837423f8f20b15',\n",
      "                  'motion': {   'algorithm': '@withinFile_withinFrame_lucasKanade',\n",
      "                                'correct_motion': True,\n",
      "                                'destdir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002/mcorrected',\n",
      "                                'method': 'Acquisition2P',\n",
      "                                'ref_channel': 0,\n",
      "                                'ref_file': 0,\n",
      "                                'sourcedir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002/bidi'},\n",
      "                  'preprocessing': {   'correct_bidir': True,\n",
      "                                       'correct_flyback': True,\n",
      "                                       'destdir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002/bidi',\n",
      "                                       'nflyback_frames': 0,\n",
      "                                       'sourcedir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002/raw',\n",
      "                                       'split_channels': False},\n",
      "                  'source': {   'acquisition': 'FOV1_zoom3x',\n",
      "                                'animalid': 'CE059',\n",
      "                                'rootdir': '/nas/volume1/2photon/data',\n",
      "                                'run': 'gratings_run1',\n",
      "                                'session': '20171009_CE059',\n",
      "                                'tiffsource': 'raw'}},\n",
      "    'SRC': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/raw',\n",
      "    'process_id': 'processed002',\n",
      "    'tmp_hashid': 'd2342f',\n",
      "    'version': '0.1.0'}\n"
     ]
    }
   ],
   "source": [
    "    acquisition_dir = os.path.join(rootdir, animalid, session, acquisition)\n",
    "    # Generate new process_id based on input params:\n",
    "    pid = initialize_pid(PARAMS, acquisition_dir, run)\n",
    "    pp.pprint(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      "Updating JSONS...\n",
      "************************\n",
      "Process Info UPDATED.\n"
     ]
    }
   ],
   "source": [
    "update_records(pid, acquisition_dir, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # STORE TMP FILE OF CURRENT PARAMS:\n",
    "    tmp_pid_fn = 'tmp_pid_%s.json' % pid['tmp_hashid'][0:6]\n",
    "    tmp_pid_dir = os.path.join(acquisition_dir, run, 'processed', 'tmp_pids')\n",
    "    if not os.path.exists(tmp_pid_dir):\n",
    "        os.makedirs(tmp_pid_dir)\n",
    "    with open(os.path.join(tmp_pid_dir, tmp_pid_fn), 'w') as f:\n",
    "        json.dump(pid, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DST': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002',\n",
       " 'PARAMS': {'hashid': '06e4b48390af95a507582e5866837423f8f20b15',\n",
       "  'motion': {'algorithm': '@withinFile_withinFrame_lucasKanade',\n",
       "   'correct_motion': True,\n",
       "   'destdir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002/mcorrected',\n",
       "   'method': 'Acquisition2P',\n",
       "   'ref_channel': 0,\n",
       "   'ref_file': 0,\n",
       "   'sourcedir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002/bidi'},\n",
       "  'preprocessing': {'correct_bidir': True,\n",
       "   'correct_flyback': True,\n",
       "   'destdir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002/bidi',\n",
       "   'nflyback_frames': 0,\n",
       "   'sourcedir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002/raw',\n",
       "   'split_channels': False},\n",
       "  'source': {'acquisition': 'FOV1_zoom3x',\n",
       "   'animalid': 'CE059',\n",
       "   'rootdir': '/nas/volume1/2photon/data',\n",
       "   'run': 'gratings_run1',\n",
       "   'session': '20171009_CE059',\n",
       "   'tiffsource': 'raw'}},\n",
       " 'SRC': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/raw',\n",
       " 'process_id': 'processed002',\n",
       " 'tmp_hashid': 'd2342f',\n",
       " 'version': '0.1.0'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'raw'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pid['PARAMS']['source']['tiffsource']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def append_hash_to_paths(PID, pid_hash, step=''):\n",
    "    correct_flyback = PID['PARAMS']['preprocessing']['correct_flyback']\n",
    "    correct_bidir = PID['PARAMS']['preprocessing']['correct_bidir']\n",
    "    correct_motion = PID['PARAMS']['motion']['correct_motion']\n",
    "\n",
    "    # If get_scanimage_data.py not run, <rundir>/raw/ does not have hash:\n",
    "    if PID['PARAMS']['source']['tiffsource'] == 'raw':\n",
    "        rawtiff_dir = PID['SRC']\n",
    "        rawtiff_hashdir = [r for r in os.listdir(os.path.split(PID['SRC'])[0]) if 'raw_' in r]\n",
    "        if len(rawtiff_hashdir)== 1:\n",
    "            rawtiff_dir = os.path.join(os.path.split(PID['SRC'])[0], rawtiff_hashdir[0])\n",
    "        elif os.path.exists(rawtiff_dir):\n",
    "            # No hash created, yet, since renaming hasn't occured (default is 'raw')\n",
    "            print \"Checking tiffdir hash...\"\n",
    "            rawdir_hash = write_hash_readonly(rawtiff_hashdir, PID=None, step='simeta')\n",
    "            if rawdir_hash not in rawtiff_dir:\n",
    "                rawtiff_dir = rawtiff_dir + '_%s' % rawdir_hash\n",
    "                print \"Got hash for RAW dir:\", rawtiff_dir\n",
    "        PID['SRC'] = rawtiff_dir\n",
    "        \n",
    "    if pid_hash not in PID['DST']:\n",
    "        PID['DST'] = PID['DST'] + '_%s' % pid_hash\n",
    "    print 'PID %s: SRC is %s' % (pid_hash, PID['SRC'])\n",
    "    print 'PID %s: DST is %s' % (pid_hash, PID['DST'])\n",
    "\n",
    "    # Update source/dest, depending on current step and params:\n",
    "    if step == 'flyback':\n",
    "        PID['PARAMS']['preprocessing']['sourcedir'] = PID['SRC']\n",
    "        if correct_flyback is True:\n",
    "            PID['PARAMS']['preprocessing']['destdir'] = os.path.join(PID['DST'], 'raw')\n",
    "\n",
    "    if step == 'bidir':\n",
    "        if correct_flyback is True:\n",
    "            # Bidir-correction is on flyback-corrected tiffs:\n",
    "            PID['PARAMS']['preprocessing']['sourcedir'] = copy.copy(PID['PARAMS']['preprocessing']['destdir'])\n",
    "            if '_' not in PID['PARAMS']['preprocessing']['sourcedir'] and\\\n",
    "                                os.path.isdir(PID['PARAMS']['preprocessing']['sourcedir']):\n",
    "                PID = write_hash_readonly(PID['PARAMS']['preprocessing']['sourcedir'],\n",
    "                                              PID=PID, step='preprocessing', label='bidir')\n",
    "        else:\n",
    "            # Bidir-correction is raw/SRC tiffs:\n",
    "            PID['PARAMS']['preprocessing']['sourcedir'] = copy.copy(PID['SRC'])\n",
    "\n",
    "        PID['PARAMS']['preprocessing']['destdir'] = os.path.join(PID['DST'], 'bidi')\n",
    "\n",
    "    if step == 'motion':\n",
    "        if correct_bidir is True:\n",
    "            PID['PARAMS']['motion']['sourcedir'] = copy.copy(PID['PARAMS']['preprocessing']['sourcedir'])\n",
    "        else:\n",
    "            PID['PARAMS']['motion']['sourcedir'] = copy.copy(PID['SRC'])\n",
    "\n",
    "        PID['PARAMS']['motion']['destdir'] = os.path.join(PID['DST'], 'mcorrected')\n",
    "\n",
    "    return PID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_hash_readonly(write_dir, PID=None, step='', label=''):\n",
    "    write_hash = None\n",
    "    excluded_files = [str(f) for f in os.listdir(write_dir) if not f.endswith('tif')]\n",
    "    print \"Checking %s hash, excluded_files:\" % label, excluded_files\n",
    "    write_hash = dirhash(write_dir, 'sha1', excluded_files=excluded_files)[0:6]\n",
    "    newwrite_dir = write_dir + '_%s' % write_hash\n",
    "    \n",
    "    # Rename dir if hash is not included:\n",
    "    if write_hash not in write_dir:\n",
    "        os.rename(write_dir, newwrite_dir)\n",
    "\n",
    "    # Set READ-ONLY permissions:\n",
    "    for f in os.listdir(newwrite_dir):\n",
    "        os.chmod(os.path.join(newwrite_dir, f), S_IREAD|S_IRGRP|S_IROTH)  \n",
    "        \n",
    "    if PID is not None:\n",
    "        if write_hash not in PID['PARAMS'][step]['destdir']:\n",
    "            PID['PARAMS'][step]['destdir'] = newwrite_dir\n",
    "        print \"PID %s: Renamed output dir: %s\" % (PID['tmp_hashid'], PID['PARAMS'][step]['destdir'])\n",
    "    \n",
    "    return write_hash, PID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DST': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002',\n",
       " 'PARAMS': {'hashid': '06e4b48390af95a507582e5866837423f8f20b15',\n",
       "  'motion': {'algorithm': '@withinFile_withinFrame_lucasKanade',\n",
       "   'correct_motion': True,\n",
       "   'destdir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002/mcorrected',\n",
       "   'method': 'Acquisition2P',\n",
       "   'ref_channel': 0,\n",
       "   'ref_file': 0,\n",
       "   'sourcedir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002/bidi'},\n",
       "  'preprocessing': {'correct_bidir': True,\n",
       "   'correct_flyback': True,\n",
       "   'destdir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002/bidi',\n",
       "   'nflyback_frames': 0,\n",
       "   'sourcedir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002/raw',\n",
       "   'split_channels': False},\n",
       "  'source': {'acquisition': 'FOV1_zoom3x',\n",
       "   'animalid': 'CE059',\n",
       "   'rootdir': '/nas/volume1/2photon/data',\n",
       "   'run': 'gratings_run1',\n",
       "   'session': '20171009_CE059',\n",
       "   'tiffsource': 'raw'}},\n",
       " 'SRC': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/raw',\n",
       " 'process_id': 'processed002',\n",
       " 'tmp_hashid': 'd2342f',\n",
       " 'version': '0.1.0'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID d2342f: SRC is /nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/raw_b7b5d9\n",
      "PID d2342f: DST is /nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002_d2342f\n",
      "{   'DST': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002_d2342f',\n",
      "    'PARAMS': {   'hashid': '06e4b48390af95a507582e5866837423f8f20b15',\n",
      "                  'motion': {   'algorithm': '@withinFile_withinFrame_lucasKanade',\n",
      "                                'correct_motion': True,\n",
      "                                'destdir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002/mcorrected',\n",
      "                                'method': 'Acquisition2P',\n",
      "                                'ref_channel': 0,\n",
      "                                'ref_file': 0,\n",
      "                                'sourcedir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002/bidi'},\n",
      "                  'preprocessing': {   'correct_bidir': True,\n",
      "                                       'correct_flyback': True,\n",
      "                                       'destdir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002_d2342f/raw',\n",
      "                                       'nflyback_frames': 0,\n",
      "                                       'sourcedir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/raw_b7b5d9',\n",
      "                                       'split_channels': False},\n",
      "                  'source': {   'acquisition': 'FOV1_zoom3x',\n",
      "                                'animalid': 'CE059',\n",
      "                                'rootdir': '/nas/volume1/2photon/data',\n",
      "                                'run': 'gratings_run1',\n",
      "                                'session': '20171009_CE059',\n",
      "                                'tiffsource': 'raw'}},\n",
      "    'SRC': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/raw_b7b5d9',\n",
      "    'process_id': 'processed002',\n",
      "    'tmp_hashid': 'd2342f',\n",
      "    'version': '0.1.0'}\n"
     ]
    }
   ],
   "source": [
    "pid_hash = 'd2342f'\n",
    "pid_fb = append_hash_to_paths(pid, pid_hash, step='flyback')\n",
    "pp.pprint(pid_fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID d2342f: SRC is /nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/raw_b7b5d9\n",
      "PID d2342f: DST is /nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002_d2342f\n",
      "{   'DST': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002_d2342f',\n",
      "    'PARAMS': {   'hashid': '06e4b48390af95a507582e5866837423f8f20b15',\n",
      "                  'motion': {   'algorithm': '@withinFile_withinFrame_lucasKanade',\n",
      "                                'correct_motion': True,\n",
      "                                'destdir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002/mcorrected',\n",
      "                                'method': 'Acquisition2P',\n",
      "                                'ref_channel': 0,\n",
      "                                'ref_file': 0,\n",
      "                                'sourcedir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002/bidi'},\n",
      "                  'preprocessing': {   'correct_bidir': True,\n",
      "                                       'correct_flyback': True,\n",
      "                                       'destdir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002_d2342f/bidi',\n",
      "                                       'nflyback_frames': 0,\n",
      "                                       'sourcedir': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/processed/processed002_d2342f/raw',\n",
      "                                       'split_channels': False},\n",
      "                  'source': {   'acquisition': 'FOV1_zoom3x',\n",
      "                                'animalid': 'CE059',\n",
      "                                'rootdir': '/nas/volume1/2photon/data',\n",
      "                                'run': 'gratings_run1',\n",
      "                                'session': '20171009_CE059',\n",
      "                                'tiffsource': 'raw'}},\n",
      "    'SRC': '/nas/volume1/2photon/data/CE059/20171009_CE059/FOV1_zoom3x/gratings_run1/raw_b7b5d9',\n",
      "    'process_id': 'processed002',\n",
      "    'tmp_hashid': 'd2342f',\n",
      "    'version': '0.1.0'}\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "pid_bd = append_hash_to_paths(pid_fb, pid_hash, step='bidir')\n",
    "pp.pprint(pid_bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
