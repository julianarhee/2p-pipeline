{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import optparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pyvttbl as pt\n",
    "import multiprocessing as mp\n",
    "import tifffile as tf\n",
    "from collections import namedtuple\n",
    "from scipy import stats\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "from pipeline.python.utils import natural_keys, replace_root, print_elapsed_time\n",
    "import pipeline.python.traces.combine_runs as cb\n",
    "import pipeline.python.paradigm.align_acquisition_events as acq\n",
    "import pipeline.python.visualization.plot_psths_from_dataframe as vis\n",
    "from pipeline.python.traces.utils import load_TID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juliana/anaconda/envs/pipeline/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%%\n",
    "def load_roi_dataframe(roidata_filepath):\n",
    "\n",
    "    fn_parts = os.path.split(roidata_filepath)[-1].split('_')\n",
    "    roidata_hash = fn_parts[1]\n",
    "    trace_type = os.path.splitext(fn_parts[-1])[0]\n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    df = pd.HDFStore(roidata_filepath, 'r')\n",
    "    datakeys = df.keys()\n",
    "    if 'roi' in datakeys[0]:\n",
    "        for roi in datakeys:\n",
    "            if '/' in roi:\n",
    "                roiname = roi[1:]\n",
    "            else:\n",
    "                roiname = roi\n",
    "            dfr = df[roi]\n",
    "            dfr['roi'] = pd.Series(np.tile(roiname, (len(dfr .index),)), index=dfr.index)\n",
    "            df_list.append(dfr)\n",
    "        DATA = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "        datakey = '%s_%s' % (trace_type, roidata_hash)\n",
    "    else:\n",
    "        print \"Found %i datakeys\" % len(datakeys)\n",
    "        datakey = datakeys[0]\n",
    "        df.close()\n",
    "        del df\n",
    "        DATA = pd.read_hdf(roidata_filepath, datakey)\n",
    "        #DATA = df[datakey]\n",
    "\n",
    "    return DATA, datakey\n",
    "\n",
    "#%%\n",
    "\n",
    "def pyvt_raw_epochXoriXsf(rdata, trans_types, save_fig=False, output_dir='/tmp', fname='boxplot(intensity~epoch_X_config).png'):\n",
    "\n",
    "    # Make sure trans_types are sorted:\n",
    "    trans_types = sorted(trans_types, key=natural_keys)\n",
    "\n",
    "    assert len(list(set(rdata['nframes_on'])))==1, \"More than 1 idx found for nframes on... %s\" % str(list(set(rdata['nframes_on'])))\n",
    "    assert len(list(set(rdata['first_on'])))==1, \"More than 1 idx found for first frame on... %s\" % str(list(set(rdata['first_on'])))\n",
    "\n",
    "    nframes_on = int(round(list(set(rdata['nframes_on']))[0]))\n",
    "    first_on =  int(round(list(set(rdata['first_on']))[0]))\n",
    "\n",
    "    df_groups = np.copy(trans_types).tolist()\n",
    "    df_groups.extend(['trial', 'raw'])\n",
    "    groupby_list = np.copy(trans_types).tolist()\n",
    "    groupby_list.extend(['trial'])\n",
    "\n",
    "    currdf = rdata[df_groups] #.sort_values(trans_types)\n",
    "    grp = currdf.groupby(groupby_list)\n",
    "    config_trials = {} # dict((config, []) for config in list(set(currdf['config'])))\n",
    "    for k,g in grp: #config_trials.keys():\n",
    "        if k[0] not in config_trials.keys():\n",
    "            config_trials[k[0]] = {}\n",
    "        if k[1] not in config_trials[k[0]].keys():\n",
    "            config_trials[k[0]][k[1]] = {}\n",
    "\n",
    "        config_trials[k[0]][k[1]] = sorted(list(set(currdf.loc[(currdf['ori']==k[0])\n",
    "                                                        & (currdf['sf']==k[1])]['trial'])), key=natural_keys)\n",
    "\n",
    "    idx = 0\n",
    "    df_list = []\n",
    "    for k,g in grp:\n",
    "        #print k\n",
    "        base_mean= g['raw'][0:first_on].mean()\n",
    "        base_std = g['raw'][0:first_on].std()\n",
    "        stim_mean = g['raw'][first_on:first_on+nframes_on].mean()\n",
    "\n",
    "        df_list.append(pd.DataFrame({'ori': k[0],\n",
    "                                     'sf': k[1],\n",
    "                                     'trial': 'trial%05d' % int(config_trials[k[0]][k[1]].index(k[2]) + 1),\n",
    "                                     'epoch': 'baseline',\n",
    "                                     'intensity': base_mean}, index=[idx]))\n",
    "        df_list.append(pd.DataFrame({'ori': k[0],\n",
    "                                     'sf': k[1],\n",
    "                                     'trial': 'trial%05d' % int(config_trials[k[0]][k[1]].index(k[2]) + 1),\n",
    "                                     'epoch': 'stimulus',\n",
    "                                     'intensity': stim_mean}, index=[idx+1]))\n",
    "        idx += 2\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    df = df.sort_values(['epoch', 'ori', 'sf'])\n",
    "    df = df.reset_index(drop=True)\n",
    "    #pdf.pivot_table(index=['trial'], columns=['config', 'epoch'], values='intensity')\n",
    "\n",
    "    # Format pandas df into pyvttbl dataframe:\n",
    "    df_factors = np.copy(trans_types).tolist()\n",
    "    df_factors.extend(['trial', 'epoch', 'intensity'])\n",
    "\n",
    "    Trial = namedtuple('Trial', df_factors)\n",
    "    pdf = pt.DataFrame()\n",
    "    for idx in xrange(df.shape[0]):\n",
    "        pdf.insert(Trial(df.loc[idx, 'ori'],\n",
    "                         df.loc[idx, 'sf'],\n",
    "                         df.loc[idx, 'trial'],\n",
    "                         df.loc[idx, 'epoch'],\n",
    "                         df.loc[idx, 'intensity'])._asdict())\n",
    "\n",
    "    if save_fig:\n",
    "        factor_list = np.copy(trans_types).tolist()\n",
    "        factor_list.extend(['epoch'])\n",
    "        pdf.box_plot('intensity', factors=factor_list, fname=fname, output_dir=output_dir)\n",
    "\n",
    "    return pdf\n",
    "#%%\n",
    "def pyvt_stimdf_oriXsf(rdata, trans_types, save_fig=False, output_dir='/tmp', fname='dff_boxplot(intensity~epoch_X_config).png'):\n",
    "\n",
    "    # Make sure trans_types are sorted:\n",
    "    trans_types = sorted(trans_types, key=natural_keys)\n",
    "\n",
    "    assert len(list(set(rdata['nframes_on'])))==1, \"More than 1 idx found for nframes on... %s\" % str(list(set(rdata['nframes_on'])))\n",
    "    assert len(list(set(rdata['first_on'])))==1, \"More than 1 idx found for first frame on... %s\" % str(list(set(rdata['first_on'])))\n",
    "\n",
    "    nframes_on = int(round(list(set(rdata['nframes_on']))[0]))\n",
    "    first_on =  int(round(list(set(rdata['first_on']))[0]))\n",
    "\n",
    "    df_groups = np.copy(trans_types).tolist()\n",
    "    df_groups.extend(['trial', 'df'])\n",
    "    groupby_list = np.copy(trans_types).tolist()\n",
    "    groupby_list.extend(['trial'])\n",
    "\n",
    "    currdf = rdata[df_groups] #.sort_values(trans_types)\n",
    "    grp = currdf.groupby(groupby_list)\n",
    "    config_trials = {} # dict((config, []) for config in list(set(currdf['config'])))\n",
    "    for k,g in grp: #config_trials.keys():\n",
    "        if k[0] not in config_trials.keys():\n",
    "            config_trials[k[0]] = {}\n",
    "        if k[1] not in config_trials[k[0]].keys():\n",
    "            config_trials[k[0]][k[1]] = {}\n",
    "\n",
    "        config_trials[k[0]][k[1]] = sorted(list(set(currdf.loc[(currdf['ori']==k[0])\n",
    "                                                        & (currdf['sf']==k[1])]['trial'])), key=natural_keys)\n",
    "\n",
    "    idx = 0\n",
    "    df_list = []\n",
    "    for k,g in grp:\n",
    "        #print k\n",
    "        base_mean= g['df'][0:first_on].mean()\n",
    "        base_std = g['df'][0:first_on].std()\n",
    "        stim_mean = g['df'][first_on:first_on+nframes_on].mean()\n",
    "        zscore_val = stim_mean / base_std\n",
    "\n",
    "        df_list.append(pd.DataFrame({'ori': k[0],\n",
    "                                     'sf': k[1],\n",
    "                                     'trial': k[2], #'trial%05d' % int(config_trials[k[0]][k[1]].index(k[2]) + 1),\n",
    "                                     'dff': stim_mean,\n",
    "                                     'zscore': zscore_val}, index=[idx]))\n",
    "\n",
    "        idx += 1\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    df = df.sort_values(trans_types)\n",
    "    df = df.reset_index(drop=True)\n",
    "    #pdf.pivot_table(index=['trial'], columns=['config', 'epoch'], values='intensity')\n",
    "\n",
    "    # Format pandas df into pyvttbl dataframe:\n",
    "    df_factors = np.copy(trans_types).tolist()\n",
    "    df_factors.extend(['trial', 'dff'])\n",
    "\n",
    "    Trial = namedtuple('Trial', df_factors)\n",
    "    pdf = pt.DataFrame()\n",
    "    for idx in xrange(df.shape[0]):\n",
    "        pdf.insert(Trial(df.loc[idx, 'ori'],\n",
    "                         df.loc[idx, 'sf'],\n",
    "                         df.loc[idx, 'trial'],\n",
    "                         df.loc[idx, 'dff'])._asdict())\n",
    "\n",
    "    if save_fig:\n",
    "        factor_list = np.copy(trans_types).tolist()\n",
    "        pdf.box_plot('dff', factors=factor_list, fname=fname, output_dir=output_dir)\n",
    "\n",
    "    return pdf\n",
    "\n",
    "#%%\n",
    "def pyvt_stimdf_configs(rdata, save_fig=False, output_dir='/tmp', fname='boxplot(intensity~epoch_X_config).png'):\n",
    "\n",
    "    '''\n",
    "    Take single ROI as a datatset, do split-plot rmANOVA:\n",
    "        within-trial factor :  baseline vs. stimulus epoch\n",
    "        between-trial factor :  stimulus condition\n",
    "    '''\n",
    "\n",
    "    assert len(list(set(rdata['nframes_on'])))==1, \"More than 1 idx found for nframes on... %s\" % str(list(set(rdata['nframes_on'])))\n",
    "    assert len(list(set(rdata['first_on'])))==1, \"More than 1 idx found for first frame on... %s\" % str(list(set(rdata['first_on'])))\n",
    "\n",
    "    nframes_on = int(round(list(set(rdata['nframes_on']))[0]))\n",
    "    first_on =  int(round(list(set(rdata['first_on']))[0]))\n",
    "\n",
    "    df_groups = ['config', 'trial', 'df']\n",
    "    groupby_list = ['config', 'trial']\n",
    "\n",
    "    currdf = rdata[df_groups] #.sort_values(trans_types)\n",
    "    grp = currdf.groupby(groupby_list)\n",
    "    config_trials = {} # dict((config, []) for config in list(set(currdf['config'])))\n",
    "    for k,g in grp: #config_trials.keys():\n",
    "        if k[0] not in config_trials.keys():\n",
    "            config_trials[k[0]] = {}\n",
    "\n",
    "        config_trials[k[0]] = sorted(list(set(currdf.loc[currdf['config']==k[0]]['trial'])), key=natural_keys)\n",
    "\n",
    "    idx = 0\n",
    "    df_list = []\n",
    "    for k,g in grp:\n",
    "        #print k\n",
    "        base_mean= g['df'][0:first_on].mean()\n",
    "        base_std = g['df'][0:first_on].std()\n",
    "        stim_mean = g['df'][first_on:first_on+nframes_on].mean()\n",
    "\n",
    "        df_list.append(pd.DataFrame({'config': k[0],\n",
    "                                     'trial': k[1], #'trial%05d' % int(config_trials[k[0]].index(k[1]) + 1),\n",
    "                                     'dff': stim_mean}, index=[idx]))\n",
    "        idx += 1\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    df = df.sort_values(['config'])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    #pdf.pivot_table(index=['trial'], columns=['config', 'epoch'], values='intensity')\n",
    "\n",
    "    # Format pandas df into pyvttbl dataframe:\n",
    "    df_factors = ['config', 'trial', 'dff']\n",
    "\n",
    "    Trial = namedtuple('Trial', df_factors)\n",
    "    pdf = pt.DataFrame()\n",
    "    for idx in xrange(df.shape[0]):\n",
    "        pdf.insert(Trial(df.loc[idx, 'config'],\n",
    "                         df.loc[idx, 'trial'],\n",
    "                         df.loc[idx, 'dff'])._asdict())\n",
    "\n",
    "    if save_fig:\n",
    "        factor_list = ['config']\n",
    "        pdf.box_plot('dff', factors=factor_list, fname=fname, output_dir=output_dir)\n",
    "\n",
    "    return pdf\n",
    "\n",
    "#%%\n",
    "def roidata_to_df_configs(rdata):\n",
    "\n",
    "    '''\n",
    "    Take subset of full ROIDATA dataframe using specified columns.\n",
    "    Convert DF to make compatible w/ pyvttbl (and other).\n",
    "    '''\n",
    "\n",
    "    assert len(list(set(rdata['nframes_on'])))==1, \"More than 1 idx found for nframes on... %s\" % str(list(set(rdata['nframes_on'])))\n",
    "    assert len(list(set(rdata['first_on'])))==1, \"More than 1 idx found for first frame on... %s\" % str(list(set(rdata['first_on'])))\n",
    "\n",
    "    nframes_on = int(round(list(set(rdata['nframes_on']))[0]))\n",
    "    first_on =  int(round(list(set(rdata['first_on']))[0]))\n",
    "\n",
    "    df_groups = ['config', 'trial', 'df']\n",
    "    groupby_list = ['config', 'trial']\n",
    "\n",
    "    currdf = rdata[df_groups] #.sort_values(trans_types)\n",
    "    grp = currdf.groupby(groupby_list)\n",
    "    config_trials = {} # dict((config, []) for config in list(set(currdf['config'])))\n",
    "    for k,g in grp: #config_trials.keys():\n",
    "        if k[0] not in config_trials.keys():\n",
    "            config_trials[k[0]] = {}\n",
    "\n",
    "        config_trials[k[0]] = sorted(list(set(currdf.loc[currdf['config']==k[0]]['trial'])), key=natural_keys)\n",
    "\n",
    "    idx = 0\n",
    "    df_list = []\n",
    "    for k,g in grp:\n",
    "        #print k\n",
    "        base_mean= g['df'][0:first_on].mean()\n",
    "        base_std = g['df'][0:first_on].std()\n",
    "        stim_mean = g['df'][first_on:first_on+nframes_on].mean()\n",
    "\n",
    "        df_list.append(pd.DataFrame({'config': k[0],\n",
    "                                     'trial': k[1], #'trial%05d' % int(config_trials[k[0]].index(k[1]) + 1),\n",
    "                                     'dff': stim_mean,\n",
    "                                     'zscore': stim_mean / base_std}, index=[idx]))\n",
    "        idx += 2\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    df = df.sort_values(['config'])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "#%%\n",
    "\n",
    "def roidata_to_df_transforms(rdata, trans_types):\n",
    "\n",
    "    '''\n",
    "    Take subset of full ROIDATA dataframe using specified columns.\n",
    "    Convert DF to make compatible w/ pyvttbl (and other).\n",
    "    '''\n",
    "\n",
    "    assert len(list(set(rdata['nframes_on'])))==1, \"More than 1 idx found for nframes on... %s\" % str(list(set(rdata['nframes_on'])))\n",
    "    assert len(list(set(rdata['first_on'])))==1, \"More than 1 idx found for first frame on... %s\" % str(list(set(rdata['first_on'])))\n",
    "\n",
    "    nframes_on = int(round(list(set(rdata['nframes_on']))[0]))\n",
    "    first_on =  int(round(list(set(rdata['first_on']))[0]))\n",
    "\n",
    "    # Check if 'xpos' or 'ypos' in trans_types, replace with 'position':\n",
    "#    if 'xpos' in trans_types or 'ypos' in trans_types:\n",
    "#        trans_types.extend(['position'])\n",
    "#        trans_types = [t for t in trans_types if not (t == 'xpos') and not (t == 'ypos')]\n",
    "    # Make sure trans_types sorted:\n",
    "    trans_types = sorted(trans_types, key=natural_keys)\n",
    "\n",
    "    df_groups = np.copy(trans_types).tolist()\n",
    "    df_groups.extend(['trial', 'df'])\n",
    "    currdf = rdata[df_groups] #.sort_values(trans_types)\n",
    "\n",
    "    groupby_list = np.copy(trans_types).tolist()\n",
    "    groupby_list.extend(['trial'])\n",
    "    grp = currdf.groupby(groupby_list)\n",
    "#    config_trials = {} # dict((config, []) for config in list(set(currdf['config'])))\n",
    "#    for k,g in grp: #config_trials.keys():\n",
    "#        if k[0] not in config_trials.keys():\n",
    "#            config_trials[k[0]] = {}\n",
    "#        config_trials[k[0]] = sorted(list(set(currdf.loc[currdf['config']==k[0]]['trial'])), key=natural_keys)\n",
    "\n",
    "    idx = 0\n",
    "    df_list = []\n",
    "    for k,g in grp:\n",
    "        #print k\n",
    "        base_mean= g['df'][0:first_on].mean()\n",
    "        base_std = g['df'][0:first_on].std()\n",
    "        stim_mean = g['df'][first_on:first_on+nframes_on].mean()\n",
    "\n",
    "        tdict = {'trial': k[-1],\n",
    "                 'dff': stim_mean,\n",
    "                 'zscore': stim_mean / base_std}\n",
    "        for dkey in range(len(k)-1):\n",
    "            tdict[trans_types[dkey]] = k[dkey]\n",
    "\n",
    "        df_list.append(pd.DataFrame(tdict, index=[idx]))\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    df = df.sort_values(trans_types)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "#%%\n",
    "\n",
    "def roidata_to_factors(rdata):\n",
    "\n",
    "    '''\n",
    "    Take subset of full ROIDATA dataframe using specified columns.\n",
    "    Create DF of shape:  rows = replications (subjects, trials, etc.)\n",
    "                         columns = conditions (A1B1, A1B2, A1B3, ... A1Bb, A2B1, A2B2, ... A2Bb, ... AaBb)\n",
    "                         where a = num levels for factor A (epoch: baseline vs stimulus period),\n",
    "                               b = num levels for factor B (config)\n",
    "    '''\n",
    "\n",
    "    assert len(list(set(rdata['nframes_on'])))==1, \"More than 1 idx found for nframes on... %s\" % str(list(set(rdata['nframes_on'])))\n",
    "    assert len(list(set(rdata['first_on'])))==1, \"More than 1 idx found for first frame on... %s\" % str(list(set(rdata['first_on'])))\n",
    "\n",
    "\n",
    "    nframes_on = int(round(list(set(rdata['nframes_on']))[0]))\n",
    "    first_on =  int(round(list(set(rdata['first_on']))[0]))\n",
    "\n",
    "    df_groups = ['config', 'trial', 'raw']\n",
    "\n",
    "    currdf = rdata[df_groups] #.sort_values(trans_types)\n",
    "\n",
    "    grp = currdf.groupby(['config', 'trial'])\n",
    "\n",
    "    conditions = list(set(currdf['config']))\n",
    "    df_list = []\n",
    "    for cond in conditions:\n",
    "        curr_trials = [k for k in grp.groups.keys() if k[0] == cond]\n",
    "        baseline_vals = [grp.get_group(t)['raw'][0:first_on].mean() for t in curr_trials]\n",
    "        stimulus_vals = [grp.get_group(t)['raw'][first_on:first_on+nframes_on].mean() for t in curr_trials]\n",
    "        df_list.append(pd.DataFrame({'bas_%s' % cond: baseline_vals},\n",
    "                                     index=np.arange(0,len(curr_trials))\n",
    "                                     ))\n",
    "        df_list.append(pd.DataFrame({'stim_%s' % cond: stimulus_vals},\n",
    "                                     index=np.arange(0,len(curr_trials))\n",
    "                                     ))\n",
    "    df = pd.concat(df_list, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "#D = {}\n",
    "#D[roi] = df.values[0:-1,:]\n",
    "#mfile_path = os.path.join('/home', 'juliana', 'Downloads', 'rdata1.mat')\n",
    "#scipy.io.savemat(mfile_path, D)\n",
    "\n",
    "#%%\n",
    "def roidata_to_epochXconfig(rdata, save_fig=False, output_dir='/tmp', fname='boxplot(intensity~epoch_X_config).png'):\n",
    "\n",
    "    '''\n",
    "    Take single ROI as a datatset, do split-plot rmANOVA:\n",
    "        within-trial factor :  baseline vs. stimulus epoch\n",
    "        between-trial factor :  stimulus condition\n",
    "    '''\n",
    "\n",
    "    assert len(list(set(rdata['nframes_on'])))==1, \"More than 1 idx found for nframes on... %s\" % str(list(set(rdata['nframes_on'])))\n",
    "    assert len(list(set(rdata['first_on'])))==1, \"More than 1 idx found for first frame on... %s\" % str(list(set(rdata['first_on'])))\n",
    "\n",
    "    nframes_on = int(round(list(set(rdata['nframes_on']))[0]))\n",
    "    first_on =  int(round(list(set(rdata['first_on']))[0]))\n",
    "\n",
    "    df_groups = ['config', 'trial', 'raw']\n",
    "    groupby_list = ['config', 'trial']\n",
    "\n",
    "    currdf = rdata[df_groups] #.sort_values(trans_types)\n",
    "    grp = currdf.groupby(groupby_list)\n",
    "    config_trials = {} # dict((config, []) for config in list(set(currdf['config'])))\n",
    "    for k,g in grp: #config_trials.keys():\n",
    "        if k[0] not in config_trials.keys():\n",
    "            config_trials[k[0]] = {}\n",
    "\n",
    "        config_trials[k[0]] = sorted(list(set(currdf.loc[currdf['config']==k[0]]['trial'])), key=natural_keys)\n",
    "\n",
    "    idx = 0\n",
    "    df_list = []\n",
    "    for k,g in grp:\n",
    "        #print k\n",
    "        base_mean= g['raw'][0:first_on].mean()\n",
    "        base_std = g['raw'][0:first_on].std()\n",
    "        stim_mean = g['raw'][first_on:first_on+nframes_on].mean()\n",
    "\n",
    "        df_list.append(pd.DataFrame({'config': k[0], #str(k[0]),\n",
    "                                     'trial': k[1], #str(k[1]), #'trial%05d' % int(config_trials[k[0]].index(k[1]) + 1),\n",
    "                                     'epoch': 'baseline',\n",
    "                                     'intensity': base_mean}, index=[idx]))\n",
    "        df_list.append(pd.DataFrame({'config': k[0],\n",
    "                                     'trial': k[1], #'trial%05d' % int(config_trials[k[0]].index(k[1]) + 1),\n",
    "                                     'epoch': 'stimulus',\n",
    "                                     'intensity': stim_mean}, index=[idx+1]))\n",
    "        idx += 2\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    df = df.sort_values(['epoch', 'config'])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#%%\n",
    "def pd_to_pyvtt_transforms(df, trans_types):\n",
    "\n",
    "    # Format pandas df into pyvttbl dataframe:\n",
    "    #df_factors = ['config', 'trial', 'dff']\n",
    "    df_factors = np.copy(trans_types).tolist()\n",
    "    df_factors.extend(['trial', 'dff'])\n",
    "\n",
    "    Trial = namedtuple('Trial', df_factors)\n",
    "    pdf = pt.DataFrame()\n",
    "    for idx in xrange(df.shape[0]):\n",
    "        if len(trans_types)==1:\n",
    "            pdf.insert(Trial(df.loc[idx, trans_types[0]],\n",
    "                             df.loc[idx, 'trial'],\n",
    "                             df.loc[idx, 'dff'])._asdict())\n",
    "        elif len(trans_types)==2:\n",
    "            pdf.insert(Trial(df.loc[idx, trans_types[0]],\n",
    "                             df.loc[idx, trans_types[1]],\n",
    "                             df.loc[idx, 'trial'],\n",
    "                             df.loc[idx, 'dff'])._asdict())\n",
    "        elif len(trans_types)== 3:\n",
    "            pdf.insert(Trial(df.loc[idx, trans_types[0]],\n",
    "                             df.loc[idx, trans_types[1]],\n",
    "                             df.loc[idx, trans_types[2]],\n",
    "                             df.loc[idx, 'trial'],\n",
    "                             df.loc[idx, 'dff'])._asdict())\n",
    "\n",
    "    return pdf\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "def pyvt_raw_epochXconfig(rdata, save_fig=False, output_dir='/tmp', fname='boxplot(intensity~epoch_X_config).png'):\n",
    "\n",
    "    '''\n",
    "    Take single ROI as a datatset, do split-plot rmANOVA:\n",
    "        within-trial factor :  baseline vs. stimulus epoch\n",
    "        between-trial factor :  stimulus condition\n",
    "    '''\n",
    "\n",
    "    assert len(list(set(rdata['nframes_on'])))==1, \"More than 1 idx found for nframes on... %s\" % str(list(set(rdata['nframes_on'])))\n",
    "    assert len(list(set(rdata['first_on'])))==1, \"More than 1 idx found for first frame on... %s\" % str(list(set(rdata['first_on'])))\n",
    "\n",
    "    nframes_on = int(round(list(set(rdata['nframes_on']))[0]))\n",
    "    first_on =  int(round(list(set(rdata['first_on']))[0]))\n",
    "\n",
    "    df_groups = ['config', 'trial', 'raw']\n",
    "    groupby_list = ['config', 'trial']\n",
    "\n",
    "    currdf = rdata[df_groups] #.sort_values(trans_types)\n",
    "    grp = currdf.groupby(groupby_list)\n",
    "    config_trials = {} # dict((config, []) for config in list(set(currdf['config'])))\n",
    "    for k,g in grp: #config_trials.keys():\n",
    "        if k[0] not in config_trials.keys():\n",
    "            config_trials[k[0]] = {}\n",
    "\n",
    "        config_trials[k[0]] = sorted(list(set(currdf.loc[currdf['config']==k[0]]['trial'])), key=natural_keys)\n",
    "\n",
    "    idx = 0\n",
    "    df_list = []\n",
    "    for k,g in grp:\n",
    "        #print k\n",
    "        base_mean= g['raw'][0:first_on].mean()\n",
    "        base_std = g['raw'][0:first_on].std()\n",
    "        stim_mean = g['raw'][first_on:first_on+nframes_on].mean()\n",
    "\n",
    "        df_list.append(pd.DataFrame({'config': k[0], #str(k[0]),\n",
    "                                     'trial': k[1], #str(k[1]), #'trial%05d' % int(config_trials[k[0]].index(k[1]) + 1),\n",
    "                                     'epoch': 'baseline',\n",
    "                                     'intensity': base_mean}, index=[idx]))\n",
    "        df_list.append(pd.DataFrame({'config': k[0],\n",
    "                                     'trial': k[1], #'trial%05d' % int(config_trials[k[0]].index(k[1]) + 1),\n",
    "                                     'epoch': 'stimulus',\n",
    "                                     'intensity': stim_mean}, index=[idx+1]))\n",
    "        idx += 2\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    df = df.sort_values(['epoch', 'config'])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    #pdf.pivot_table(index=['trial'], columns=['config', 'epoch'], values='intensity')\n",
    "\n",
    "    # Format pandas df into pyvttbl dataframe:\n",
    "    df_factors = ['config', 'trial', 'epoch', 'intensity']\n",
    "\n",
    "    Trial = namedtuple('Trial', df_factors)\n",
    "    pdf = pt.DataFrame()\n",
    "    for idx in xrange(df.shape[0]):\n",
    "        pdf.insert(Trial(df.loc[idx, 'config'],\n",
    "                         df.loc[idx, 'trial'],\n",
    "                         df.loc[idx, 'epoch'],\n",
    "                         df.loc[idx, 'intensity'])._asdict())\n",
    "\n",
    "    if save_fig:\n",
    "        factor_list = ['config', 'epoch']\n",
    "        pdf.box_plot('intensity', factors=factor_list, fname=fname, output_dir=output_dir)\n",
    "\n",
    "    return pdf\n",
    "\n",
    "\n",
    "#%%\n",
    "def pyvt_raw_epochXsinglecond(rdata, curr_config='config001'):\n",
    "\n",
    "    '''\n",
    "    Treat single condition for single ROI as dataset, and do ANOVA with 'epoch' as factor.\n",
    "    Test for main-effect of trial epoch -- but this is just 1-way...?\n",
    "    '''\n",
    "\n",
    "    assert len(list(set(rdata['nframes_on'])))==1, \"More than 1 idx found for nframes on... %s\" % str(list(set(rdata['nframes_on'])))\n",
    "    assert len(list(set(rdata['first_on'])))==1, \"More than 1 idx found for first frame on... %s\" % str(list(set(rdata['first_on'])))\n",
    "\n",
    "    nframes_on = int(round(list(set(rdata['nframes_on']))[0]))\n",
    "    first_on =  int(round(list(set(rdata['first_on']))[0]))\n",
    "\n",
    "    df_groups = ['config', 'trial', 'raw']\n",
    "    groupby_list = ['config', 'trial']\n",
    "\n",
    "    currdf = rdata[df_groups]\n",
    "\n",
    "    # Split DF by current stimulus config:\n",
    "    currdf = currdf[currdf['config']==curr_config]\n",
    "\n",
    "    grp = currdf.groupby(groupby_list)\n",
    "    trial_list = sorted(list(set(currdf['trial'])), key=natural_keys)\n",
    "\n",
    "    idx = 0\n",
    "    df_list = []\n",
    "    for k,g in grp:\n",
    "        print k\n",
    "        base_mean= g['raw'][0:first_on].mean()\n",
    "        base_std = g['raw'][0:first_on].std()\n",
    "        stim_mean = g['raw'][first_on:first_on+nframes_on].mean()\n",
    "\n",
    "        df_list.append(pd.DataFrame({'config': k[0],\n",
    "                                     'trial': 'trial%05d' % int(trial_list.index(k[1]) + 1),\n",
    "                                     'epoch': 'baseline',\n",
    "                                     'intensity': base_mean}, index=[idx]))\n",
    "        df_list.append(pd.DataFrame({'config': k[0],\n",
    "                                     'trial': 'trial%05d' % int(trial_list.index(k[1]) + 1),\n",
    "                                     'epoch': 'stimulus',\n",
    "                                     'intensity': stim_mean}, index=[idx+1]))\n",
    "        idx += 2\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    idxs = pd.Index(xrange(0, len(df)))\n",
    "    df = df.sort_values(['epoch', 'config'])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    #pdf.pivot_table(index=['trial'], columns=['config', 'epoch'], values='intensity')\n",
    "\n",
    "    # Format pandas df into pyvttbl dataframe:\n",
    "    df_factors = ['trial', 'epoch', 'intensity']\n",
    "\n",
    "    Trial = namedtuple('Trial', df_factors)\n",
    "    pdf = pt.DataFrame()\n",
    "    for idx in xrange(df.shape[0]):\n",
    "        pdf.insert(Trial(df.loc[idx, 'trial'],\n",
    "                         df.loc[idx, 'epoch'],\n",
    "                         df.loc[idx, 'intensity'])._asdict())\n",
    "\n",
    "    return pdf\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "def extract_apa_anova2(factor, aov, values = ['F', 'mse', 'eta', 'p', 'df']):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    if not isinstance(factor, list):\n",
    "        factor = [factor]\n",
    "\n",
    "    for fac in factor:\n",
    "        fmtresults = {}\n",
    "        for key,result in aov[(fac)].iteritems():\n",
    "            if key in values:\n",
    "                fmtresults[key] = result\n",
    "\n",
    "        fmtresults['dim'] = aov.D\n",
    "\n",
    "        # Calculate partial-eta2:\n",
    "        fmtresults['eta2_p'] = aov[(fac)]['ss'] / ( aov[(fac)]['ss'] + aov[(fac)]['sse'] )\n",
    "\n",
    "        results[fac] = fmtresults\n",
    "\n",
    "    if len(results.keys()) == 1:\n",
    "        results = results[results.keys()[0]]\n",
    "\n",
    "    return results\n",
    "\n",
    "#%%\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "def LM_mixed(roi, rdata, output_dir = '/tmp', asdict=True):\n",
    "\n",
    "    df = roidata_to_epochXconfig(rdata) # re-format data so each factor is a column\n",
    "\n",
    "    formula = 'intensity ~ C(epoch) + C(config) + C(epoch):C(config)'\n",
    "\n",
    "    #model_anova = ols('intensity ~ epoch*config', data=df).fit()\n",
    "    model_anova = ols(formula, data=df).fit()\n",
    "    table = sm.stats.anova_lm(model_anova, typ=3) # Type 2 ANOVA DataFrame\n",
    "    print model_anova.summary()\n",
    "\n",
    "\n",
    "    vc = {'epoch': '0 + C(epoch)', 'config': '0 + config'}\n",
    "    #formula = 'intensity ~ C(epoch) + C(config) + C(epoch):C(config)'\n",
    "    formula = 'intensity ~ epoch + config + epoch*config'\n",
    "    model_anova2= sm.MixedLM.from_formula(formula, df, vc_formula=vc, groups=df['trial'], re_formula='1')\n",
    "\n",
    "    result_anova2 = model_anova2.fit()\n",
    "    print result_anova2.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "def splitplot_anova2_pyvt(roi, rdata, output_dir='/tmp', asdict=True):\n",
    "#    responsive_rois = {}\n",
    "\n",
    "    pdf = pyvt_raw_epochXconfig(rdata.dropna(), save_fig=False)\n",
    "    # Calculate ANOVA split-plot:\n",
    "    aov = pdf.anova('intensity', sub='trial',\n",
    "                       wfactors=['epoch'],\n",
    "                       bfactors=['config'])\n",
    "    print(aov)\n",
    "\n",
    "    aov_results_fpath = os.path.join(output_dir, 'visual_anova_results_%s.txt' % roi)\n",
    "    with open(aov_results_fpath,'wb') as f:\n",
    "        f.write(str(aov))\n",
    "    f.close()\n",
    "#    print aov_results_fpath\n",
    "\n",
    "    #etas = get_effect_sizes(aov, factor_a='epoch', factor_b='config')\n",
    "    results_epoch = extract_apa_anova2(('epoch',), aov)\n",
    "    #res_interaction = extract_apa_anova2(('epoch', 'config'), aov)\n",
    "#    if res_epoch['p'] < 0.1: # or res_interaction['p'] < 0.1:\n",
    "#        responsive_rois[roi] = {'F': res_epoch['F'], 'p': res_epoch['p']} #.append(roi)\n",
    "\n",
    "    if asdict is True:\n",
    "        return results_epoch\n",
    "    else:\n",
    "        return results_epoch['F'], results_epoch['p']\n",
    "\n",
    "\n",
    "#%%\n",
    "def id_visual_cells_mp(DATA, output_dir='/tmp', nprocs=4):\n",
    "\n",
    "    roi_list = sorted(list(set(DATA['roi'])), key=natural_keys)\n",
    "    print(\"Calculating split-plot ANOVA (factors=epoch, config) for %i rois.\" % len(roi_list))\n",
    "\n",
    "    t_eval_mp = time.time()\n",
    "\n",
    "    def worker(roi_list, DATA, output_dir, out_q):\n",
    "        \"\"\"\n",
    "        Worker function is invoked in a process. 'roi_list' is a list of\n",
    "        roi names to evaluate [rois00001, rois00002, etc.]. Results are placed\n",
    "        in a dict that is pushed to a queue.\n",
    "        \"\"\"\n",
    "        outdict = {}\n",
    "        for roi in roi_list:\n",
    "            print roi\n",
    "            rdata = DATA[DATA['roi']==roi]\n",
    "            outdict[roi] = splitplot_anova2(roi, rdata, output_dir=output_dir, asdict=True)\n",
    "        out_q.put(outdict)\n",
    "\n",
    "    # Each process gets \"chunksize' filenames and a queue to put his out-dict into:\n",
    "    out_q = mp.Queue()\n",
    "    chunksize = int(math.ceil(len(roi_list) / float(nprocs)))\n",
    "    procs = []\n",
    "\n",
    "    for i in range(nprocs):\n",
    "        p = mp.Process(target=worker,\n",
    "                       args=(roi_list[chunksize * i:chunksize * (i + 1)],\n",
    "                                       DATA,\n",
    "                                       output_dir,\n",
    "                                       out_q))\n",
    "        procs.append(p)\n",
    "        print \"Starting:\", p\n",
    "        p.start()\n",
    "\n",
    "    # Collect all results into single results dict. We should know how many dicts to expect:\n",
    "    resultdict = {}\n",
    "    for i in range(nprocs):\n",
    "        resultdict.update(out_q.get())\n",
    "\n",
    "    # Wait for all worker processes to finish\n",
    "    for p in procs:\n",
    "        print \"Finished:\", p\n",
    "        p.join()\n",
    "\n",
    "    print_elapsed_time(t_eval_mp)\n",
    "\n",
    "    return resultdict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "def id_visual_cells(DATA, save_figs=False, output_dir='/tmp'):\n",
    "    '''\n",
    "    For each ROI, do split-plot ANOVA --\n",
    "        between-groups factor :  config\n",
    "        within-groups factor :  epoch\n",
    "    Use raw intensity to avoid depence of trial-epoch values.\n",
    "    Save ANOVA results to disk.\n",
    "\n",
    "    Returns:\n",
    "        dict() -- keys are rois with p-value < 0.1, values are 'F' and 'p'\n",
    "    '''\n",
    "\n",
    "    roi_list = sorted(list(set(DATA['roi'])), key=natural_keys)\n",
    "    print(\"Calculating split-plot ANOVA (factors=epoch, config) for %i rois.\" % len(roi_list))\n",
    "\n",
    "    #curr_config = 'config006'\n",
    "\n",
    "    #pdf = pyvt_raw_epochXsinglecond(rdata, curr_config=curr_config)\n",
    "    #aov = pdf.anova('intensity', sub='trial', wfactors=['epoch'])\n",
    "    #aov1 = pdf.anova1way('intensity', 'epoch')\n",
    "\n",
    "    responsive_rois = {} #[]\n",
    "    for roi in roi_list:\n",
    "        print roi\n",
    "\n",
    "        rdata = DATA[DATA['roi']==roi]\n",
    "#        pdf = pyvt_raw_epochXconfig(rdata, save_fig=False)\n",
    "#\n",
    "#        # Calculate ANOVA split-plot:\n",
    "#        aov = pdf.anova('intensity', sub='trial',\n",
    "#                           wfactors=['epoch'],\n",
    "#                           bfactors=['config'])\n",
    "#        #print(aov)\n",
    "#\n",
    "#        aov_results_fpath = os.path.join(output_dir, 'visual_anova_results_%s.txt' % roi)\n",
    "#        with open(aov_results_fpath,'wb') as f:\n",
    "#            f.write(str(aov))\n",
    "#\n",
    "#        #etas = get_effect_sizes(aov, factor_a='epoch', factor_b='config')\n",
    "#        res_epoch = extract_apa_anova2(('epoch',), aov)\n",
    "#        #res_interaction = extract_apa_anova2(('epoch', 'config'), aov)\n",
    "##        if res_epoch['p'] < 0.1: # or res_interaction['p'] < 0.1:\n",
    "##            responsive_rois[roi] = {'F': res_epoch['F'], 'p': res_epoch['p']} #.append(roi)\n",
    "        responsive_rois[roi] = splitplot_anova2(roi, rdata, output_dir=output_dir, asdict=True)\n",
    "\n",
    "#        if roi in responsive_rois and save_figs is True:\n",
    "#            factor_list = ['config', 'epoch']\n",
    "#            fname = '%s_boxplot(intensity~epoch_X_config).png' % roi\n",
    "#            pdf.box_plot('intensity', factors=factor_list, fname=fname, output_dir=output_dir)\n",
    "\n",
    "    return responsive_rois\n",
    "\n",
    "\n",
    "#%%\n",
    "def plot_box_raw(DATA, roi_list, output_dir='/tmp'):\n",
    "\n",
    "    for roi in roi_list:\n",
    "        rdata = DATA[DATA['roi']==roi]\n",
    "        pdf = pyvt_raw_epochXconfig(rdata, save_fig=False)\n",
    "        factor_list = ['config', 'epoch']\n",
    "        fname = '%s_boxplot(intensity~epoch_X_config).png' % roi\n",
    "        pdf.box_plot('intensity', factors=factor_list, fname=fname, output_dir=output_dir)\n",
    "\n",
    "#%%\n",
    "\n",
    "def selectivity_KW(rdata, post_hoc='dunn', asdict=True):\n",
    "\n",
    "    # Get standard dataframe (not pyvttbl):\n",
    "    df = roidata_to_df_configs(rdata)\n",
    "\n",
    "    # Format dataframe and do KW test:\n",
    "    groupedconfigs = {}\n",
    "    for grp in df['config'].unique():\n",
    "        groupedconfigs[grp] = df[df['config']==grp]['dff'].values\n",
    "    args = groupedconfigs.values()\n",
    "    H, p = stats.kruskal(*args)\n",
    "\n",
    "    # Do post-hoc test:\n",
    "    if post_hoc == 'dunn':\n",
    "        pc = sp.posthoc_dunn(df, val_col='dff', group_col='config')\n",
    "    elif post_hoc == 'conover':\n",
    "        pc = sp.posthoc_conover(df, val_col='dff', group_col='config')\n",
    "\n",
    "    # Save ROI info:\n",
    "    posthoc_results = {'H': H,\n",
    "                       'p': p,\n",
    "                       'post_hoc': post_hoc,\n",
    "                       'p_rank': pc}\n",
    "    if asdict is True:\n",
    "        return posthoc_results\n",
    "    else:\n",
    "        return posthoc_results['H'], posthoc_results['p'], pc\n",
    "\n",
    "#%%\n",
    "def id_selective_cells_mp(DATA, nprocs=4):\n",
    "\n",
    "    roi_list = sorted(list(set(DATA['roi'])), key=natural_keys)\n",
    "    print(\"Calculating KW selectivity test for %i rois.\" % len(roi_list))\n",
    "\n",
    "    t_eval_mp = time.time()\n",
    "\n",
    "    def worker(roi_list, DATA, out_q):\n",
    "        \"\"\"\n",
    "        Worker function is invoked in a process. 'roi_list' is a list of\n",
    "        roi names to evaluate [rois00001, rois00002, etc.]. Results are placed\n",
    "        in a dict that is pushed to a queue.\n",
    "        \"\"\"\n",
    "        outdict = {}\n",
    "        for roi in roi_list:\n",
    "            print roi\n",
    "            rdata = DATA[DATA['roi']==roi]\n",
    "            outdict[roi] = selectivity_KW(rdata, post_hoc='dunn', asdict=True)\n",
    "        out_q.put(outdict)\n",
    "\n",
    "    # Each process gets \"chunksize' filenames and a queue to put his out-dict into:\n",
    "    out_q = mp.Queue()\n",
    "    chunksize = int(math.ceil(len(roi_list) / float(nprocs)))\n",
    "    procs = []\n",
    "\n",
    "    for i in range(nprocs):\n",
    "        p = mp.Process(target=worker,\n",
    "                       args=(roi_list[chunksize * i:chunksize * (i + 1)],\n",
    "                                       DATA,\n",
    "                                       out_q))\n",
    "        procs.append(p)\n",
    "        p.start()\n",
    "\n",
    "    # Collect all results into single results dict. We should know how many dicts to expect:\n",
    "    resultdict = {}\n",
    "    for i in range(nprocs):\n",
    "        resultdict.update(out_q.get())\n",
    "\n",
    "    # Wait for all worker processes to finish\n",
    "    for p in procs:\n",
    "        print \"Finished:\", p\n",
    "        p.join()\n",
    "\n",
    "    print_elapsed_time(t_eval_mp)\n",
    "\n",
    "    return resultdict\n",
    "\n",
    "#%%\n",
    "def id_selective_cells(DATA, roi_list, topn=10, test_normal=False, post_hoc='dunn', save_figs=False, output_dir='/tmp'):\n",
    "\n",
    "    ph_results = {}\n",
    "\n",
    "    for ridx,roi in enumerate(roi_list):\n",
    "        rdata = DATA[DATA['roi']==roi]\n",
    "\n",
    "        # Get standard dataframe (not pyvttbl):\n",
    "        df = roidata_to_df_configs(rdata)\n",
    "\n",
    "        if ridx < topn and save_figs:\n",
    "            print roi\n",
    "            #% Sort configs by mean value:\n",
    "            grped = df.groupby(['config']) #.mean()\n",
    "            df2 = pd.DataFrame({col:vals['dff'] for col,vals in grped})\n",
    "            meds = df2.median().sort_values(ascending=False)\n",
    "            df2 = df2[meds.index]\n",
    "            pl.figure(figsize=(10,5))\n",
    "            ax = sns.boxplot(data=df2)\n",
    "            pl.title(roi)\n",
    "            pl.ylabel('df/f')\n",
    "            ax.set_xticklabels(['%i deg\\n%.2f cpd\\n%s' % (stimconfigs[t.get_text()]['rotation'],\n",
    "                                                          stimconfigs[t.get_text()]['frequency'],\n",
    "                                                          t.get_text()) for t in ax.get_xticklabels()])\n",
    "\n",
    "            figname = 'box_mediandff_%s.png' % roi\n",
    "            pl.savefig(os.path.join(output_dir, figname))\n",
    "            pl.close()\n",
    "\n",
    "        normality = False\n",
    "        if test_normal:\n",
    "            k2, pn = stats.mstats.normaltest(df['dff'])\n",
    "            if pn < 0.05:\n",
    "                print(\"Normal test: p < 0.05, k=%.2f\" % k2)\n",
    "                normality = False\n",
    "            else:\n",
    "                print(\"Normal test: p > 0.05, k=%.2f\" % k2)\n",
    "                normality = True\n",
    "\n",
    "            # Check for normality:\n",
    "            if ridx < topn and save_figs:\n",
    "                pl.figure()\n",
    "                qq_res = stats.probplot(df['dff'], dist=\"norm\", plot=pl)\n",
    "                pl.title('P-P plot %s' % roi)\n",
    "                pl.text(-2, 0.3, 'p=%s' % str(pn))\n",
    "                pl.show()\n",
    "                figname = 'PPplot_%s.png' % roi\n",
    "                pl.savefig(os.path.join(output_dir, figname))\n",
    "                pl.close()\n",
    "\n",
    "            # Check if STDs are equal (ANOVA):\n",
    "            #df.groupby(['config']).std()\n",
    "\n",
    "        if normality is False:\n",
    "            # Format dataframe and do KW test:\n",
    "            groupedconfigs = {}\n",
    "            for grp in df['config'].unique():\n",
    "                groupedconfigs[grp] = df[df['config']==grp]['dff'].values\n",
    "            args = groupedconfigs.values()\n",
    "            H, p = stats.kruskal(*args)\n",
    "\n",
    "            # Do post-hoc test:\n",
    "            if post_hoc == 'dunn':\n",
    "                pc = sp.posthoc_dunn(df, val_col='dff', group_col='config')\n",
    "            elif post_hoc == 'conover':\n",
    "                pc = sp.posthoc_conover(df, val_col='dff', group_col='config')\n",
    "\n",
    "            if ridx < topn and save_figs:\n",
    "                # Plot heatmap of p-values from post-hoc test:\n",
    "                pl.figure(figsize=(10,8))\n",
    "                pl.title('%s test, %s' % (post_hoc, roi))\n",
    "                cmap = ['1', '#fb6a4a',  '#08306b',  '#4292c6', '#c6dbef']\n",
    "                heatmap_args = {'cmap': cmap, 'linewidths': 0.25, 'linecolor': '0.5',\n",
    "                                'clip_on': False, 'square': True,\n",
    "                                'cbar_ax_bbox': [0.90, 0.35, 0.02, 0.3]}\n",
    "                sp.sign_plot(pc, **heatmap_args)\n",
    "                figname = 'pvalues_%s_%s.png' % (roi, post_hoc)\n",
    "                pl.savefig(os.path.join(output_dir, figname))\n",
    "                pl.close()\n",
    "#        else:\n",
    "#\n",
    "#            # 1-way ANOVA (only valid under condNs):\n",
    "#            pdf = pyvt_stimdf_configs(rdata)\n",
    "#            aov = pdf.anova1way('dff', 'config') #\n",
    "#            print(aov)\n",
    "#\n",
    "#            tukey = pairwise_tukeyhsd(df['dff'], df['config'])\n",
    "#            print(tukey)\n",
    "\n",
    "        # Save ROI info:\n",
    "        ph_results[roi] = {'H': H,\n",
    "                           'p': p,\n",
    "                           'post_hoc': post_hoc,\n",
    "                           'p_rank': pc}\n",
    "\n",
    "    return ph_results\n",
    "\n",
    "#%%\n",
    "\n",
    "def selectivity_ANOVA2(roi, rdata, trans_types, output_dir='/tmp'):\n",
    "\n",
    "    df = roidata_to_df_transforms(rdata, trans_types)\n",
    "    pdf = pd_to_pyvtt_transforms(df, trans_types)\n",
    "\n",
    "    # Calculate ANOVA split-plot:\n",
    "    aov = pdf.anova('dff', sub='trial',\n",
    "                       bfactors=trans_types)\n",
    "    #print(aov)\n",
    "\n",
    "    aov_results_fpath = os.path.join(selective_resultsdir, 'selectivity_2wayanova_results_%s.txt' % roi)\n",
    "    with open(aov_results_fpath,'wb') as f:\n",
    "        f.write(str(aov))\n",
    "    f.close()\n",
    "\n",
    "    #etas = get_effect_sizes(aov, factor_a='epoch', factor_b='config')\n",
    "    # Identify which, if any, factors are significant:\n",
    "#    factor_types = aov.keys()\n",
    "#    res_epoch = {}\n",
    "#    for factor in factor_types:\n",
    "#        res_epoch[factor] = extract_apa_anova2(factor, aov)\n",
    "\n",
    "    res_epoch = extract_apa_anova2(factor_types, aov)\n",
    "\n",
    "\n",
    "    return res_epoch\n",
    "\n",
    "\n",
    "def id_selectivity_anova_mp(roi_list, DATA, trans_types, output_dir='/tmp', nprocs=4):\n",
    "\n",
    "    print \"Calculating %i-way ANOVA for %i rois (factors: %s)\" % (len(trans_types), len(roi_list), str(trans_types))\n",
    "\n",
    "    t_eval_mp = time.time()\n",
    "\n",
    "    def worker(roi_list, DATA, trans_types, output_dir, out_q):\n",
    "        \"\"\"\n",
    "        Worker function is invoked in a process. 'roi_list' is a list of\n",
    "        roi names to evaluate [rois00001, rois00002, etc.]. Results are placed\n",
    "        in a dict that is pushed to a queue.\n",
    "        \"\"\"\n",
    "        outdict = {}\n",
    "        for roi in roi_list:\n",
    "            print roi\n",
    "            rdata = DATA[DATA['roi']==roi]\n",
    "            outdict[roi] = selectivity_ANOVA2(roi, rdata, trans_types, output_dir=output_dir)\n",
    "        out_q.put(outdict)\n",
    "\n",
    "    # Each process gets \"chunksize' filenames and a queue to put his out-dict into:\n",
    "    out_q = mp.Queue()\n",
    "    chunksize = int(math.ceil(len(roi_list) / float(nprocs)))\n",
    "    procs = []\n",
    "\n",
    "    for i in range(nprocs):\n",
    "        p = mp.Process(target=worker,\n",
    "                       args=(roi_list[chunksize * i:chunksize * (i + 1)],\n",
    "                                       DATA,\n",
    "                                       trans_types,\n",
    "                                       output_dir,\n",
    "                                       out_q))\n",
    "        procs.append(p)\n",
    "        print \"Starting:\", p\n",
    "        p.start()\n",
    "\n",
    "    # Collect all results into single results dict. We should know how many dicts to expect:\n",
    "    resultdict = {}\n",
    "    for i in range(nprocs):\n",
    "        print \"Getting results:\", i\n",
    "        resultdict.update(out_q.get())\n",
    "\n",
    "    # Wait for all worker processes to finish\n",
    "    for p in procs:\n",
    "        print \"Finished:\", p\n",
    "        p.join()\n",
    "\n",
    "    print_elapsed_time(t_eval_mp)\n",
    "\n",
    "    return resultdict\n",
    "\n",
    "\n",
    "def id_selectivity_anova(roi_list, DATA, trans_types, output_dir='/tmp'):\n",
    "    results = {}\n",
    "\n",
    "    for roi in roi_list:\n",
    "        print roi\n",
    "        rdata = DATA[DATA['roi']==roi]\n",
    "        results[roi] = selectivity_ANOVA2(roi, rdata, trans_types, output_dir=output_dir)\n",
    "\n",
    "    return results\n",
    "\n",
    "#%%\n",
    "def uint16_to_RGB(img):\n",
    "    im = img.astype(np.float64)/img.max()\n",
    "    im = 255 * im\n",
    "    im = im.astype(np.uint8)\n",
    "    rgb = cv2.cvtColor(im, cv2.COLOR_GRAY2BGR)\n",
    "    return rgb\n",
    "\n",
    "#%%\n",
    "def assign_OSI(DATA, roi_list, stimconfigs):\n",
    "\n",
    "    selectivity = {}\n",
    "    for roi in roi_list:\n",
    "        ridx = int(roi[3:]) - 1\n",
    "\n",
    "        rdata = DATA[DATA['roi']==roi]\n",
    "\n",
    "        # Get standard dataframe (not pyvttbl):\n",
    "        df = roidata_to_df_configs(rdata)\n",
    "\n",
    "        stimdf_means = df.groupby(['config'])['dff'].mean()\n",
    "        ordered_configs = stimdf_means.sort_values(ascending=False).index\n",
    "        Rmost = stimdf_means[ordered_configs[0]]\n",
    "        Rleast = stimdf_means[ordered_configs[-1]]\n",
    "        SI = (Rmost - Rleast) / (Rmost + Rleast)\n",
    "\n",
    "        # If > 1 SF, use best one:\n",
    "        sfs = list(set([stimconfigs[config]['frequency'] for config in stimconfigs.keys()]))\n",
    "        sort_config_types = {}\n",
    "        for sf in sfs:\n",
    "            sort_config_types[sf] = sorted([config for config in stimconfigs.keys()\n",
    "                                                if stimconfigs[config]['frequency']==sf],\n",
    "                                                key=lambda x: stimconfigs[x]['rotation'])\n",
    "\n",
    "        oris = [stimconfigs[config]['rotation'] for config in sort_config_types[sf]]\n",
    "\n",
    "        orientation_list = sort_config_types[stimconfigs[ordered_configs[0]]['frequency']]\n",
    "\n",
    "        OSI = np.abs( sum([stimdf_means[cfg]*np.exp(2j*theta) for theta, cfg in zip(oris, orientation_list)]) / sum([stimdf_means[cfg] for cfg in  orientation_list]) )\n",
    "\n",
    "        selectivity[roi] = {'ridx': ridx,\n",
    "                            'SI': SI,\n",
    "                            'OSI': OSI,\n",
    "                            'ori': stimconfigs[ordered_configs[0]]['rotation']}\n",
    "\n",
    "    return selectivity\n",
    "\n",
    "#%%\n",
    "def get_reference_config(Cmax_overall, trans_types, transform_dict):\n",
    "    Cref = {}\n",
    "    if 'xpos' in trans_types:\n",
    "        xpos_tidx = trans_types.index('xpos')\n",
    "        ref_xpos = Cmax_overall[xpos_tidx]\n",
    "    else:\n",
    "        ref_xpos = transform_dict['xpos'][0]\n",
    "\n",
    "    if 'ypos' in trans_types:\n",
    "        ypos_tidx = trans_types.index('ypos')\n",
    "        ref_ypos = Cmax_overall[ypos_tidx]\n",
    "    else:\n",
    "        ref_ypos = transform_dict['ypos'][0]\n",
    "\n",
    "    if 'size' in trans_types:\n",
    "        size_tidx = trans_types.index('size')\n",
    "        ref_size = Cmax_overall[size_tidx]\n",
    "    else:\n",
    "        ref_size = transform_dict['size'][0]\n",
    "\n",
    "    if 'sf' in trans_types:\n",
    "        sf_tidx = trans_types.index('sf')\n",
    "        ref_sf = Cmax_overall[sf_tidx]\n",
    "    else:\n",
    "        if 'sf' in transform_dict.keys():\n",
    "            ref_sf = transform_dict['sf'][0]\n",
    "\n",
    "    Cref = {'xpos': ref_xpos,\n",
    "            'ypos': ref_ypos,\n",
    "            'size': ref_size}\n",
    "\n",
    "    if 'sf' in trans_types:\n",
    "        Cref['sf'] = ref_sf\n",
    "\n",
    "    return Cref\n",
    "\n",
    "#%% SELECTIVITY -- calculate a sparseness measure:\n",
    "\n",
    "# Case:  Transformations in xpos, ypos\n",
    "# Take as \"reference\" position, the x- and y-position eliciting the max response\n",
    "\n",
    "def calc_sparseness(df, trans_types, transform_dict):\n",
    "\n",
    "    stimdf_means = df.groupby(trans_types)['dff'].mean()\n",
    "    ordered_configs = stimdf_means.sort_values(ascending=False).index\n",
    "    if isinstance(ordered_configs, pd.MultiIndex):\n",
    "        ordered_configs = ordered_configs.tolist()\n",
    "    Cmax_overall = ordered_configs[0]\n",
    "\n",
    "    Cref = get_reference_config(Cmax_overall, trans_types, transform_dict)\n",
    "\n",
    "    object_resp_df = stimdf_means.copy()\n",
    "    if 'xpos' in trans_types:\n",
    "        object_resp_df = object_resp_df.xs(Cref['xpos'], level='xpos')\n",
    "    if 'ypos' in trans_types:\n",
    "        object_resp_df = object_resp_df.xs(Cref['ypos'], level='ypos')\n",
    "    if 'size' in trans_types:\n",
    "        object_resp_df = object_resp_df.xs(Cref['size'], level='size')\n",
    "    if 'sf' in trans_types:\n",
    "        object_resp_df = object_resp_df.xs(Cref['sf'], level='sf')\n",
    "\n",
    "    # TODO:  what to do if stim_df values are negative??\n",
    "    if all(object_resp_df.values < 0):\n",
    "        S = 0\n",
    "    else:\n",
    "        object_list = object_resp_df.index.tolist()\n",
    "        nobjects = len(object_list)\n",
    "        t1a = (sum([(object_resp_df[i] / nobjects) for i in object_list])**2)\n",
    "        t1b = sum([object_resp_df[i]**2/nobjects for i in object_list])\n",
    "        S = (1 - (t1a / t1b)) / (1-(1/nobjects))\n",
    "\n",
    "    sparseness_ref = {'S': S, 'object_responses': object_resp_df}\n",
    "\n",
    "    return sparseness_ref\n",
    "\n",
    "#%%\n",
    "def assign_sparseness_index_mp(roi_list, DATA, trans_types, transform_dict, nprocs=4):\n",
    "\n",
    "    print(\"Calculating SPARSENESS index for %i rois.\" % len(roi_list))\n",
    "\n",
    "    t_eval_mp = time.time()\n",
    "\n",
    "    def worker(roi_list, DATA, trans_types, transform_dict, out_q):\n",
    "        \"\"\"\n",
    "        Worker function is invoked in a process. 'roi_list' is a list of\n",
    "        roi names to evaluate [rois00001, rois00002, etc.]. Results are placed\n",
    "        in a dict that is pushed to a queue.\n",
    "        \"\"\"\n",
    "        outdict = {}\n",
    "        for roi in roi_list:\n",
    "            print roi\n",
    "            rdata = DATA[DATA['roi']==roi]\n",
    "            df = roidata_to_df_transforms(rdata, trans_types)\n",
    "            outdict[roi] = calc_sparseness(df, trans_types, transform_dict)\n",
    "        out_q.put(outdict)\n",
    "\n",
    "    # Each process gets \"chunksize' filenames and a queue to put his out-dict into:\n",
    "    out_q = mp.Queue()\n",
    "    chunksize = int(math.ceil(len(roi_list) / float(nprocs)))\n",
    "    procs = []\n",
    "\n",
    "    for i in range(nprocs):\n",
    "        p = mp.Process(target=worker,\n",
    "                       args=(roi_list[chunksize * i:chunksize * (i + 1)],\n",
    "                                       DATA,\n",
    "                                       trans_types,\n",
    "                                       transform_dict,\n",
    "                                       out_q))\n",
    "        procs.append(p)\n",
    "        p.start()\n",
    "\n",
    "    # Collect all results into single results dict. We should know how many dicts to expect:\n",
    "    resultdict = {}\n",
    "    for i in range(nprocs):\n",
    "        resultdict.update(out_q.get())\n",
    "\n",
    "    # Wait for all worker processes to finish\n",
    "    for p in procs:\n",
    "        print \"Finished:\", p\n",
    "        p.join()\n",
    "\n",
    "    print_elapsed_time(t_eval_mp)\n",
    "\n",
    "    return resultdict\n",
    "\n",
    "\n",
    "#%%\n",
    "#\n",
    "#roi = 'roi00006'\n",
    "#rdata = DATA[DATA['roi']==roi]\n",
    "#df = roidata_to_df_transforms(rdata, trans_types)\n",
    "#\n",
    "#stimdf_means = df.groupby(trans_types)['dff'].mean()\n",
    "#\n",
    "\n",
    "#%%\n",
    "def extract_options(options):\n",
    "\n",
    "    parser = optparse.OptionParser()\n",
    "\n",
    "    parser.add_option('-D', '--root', action='store', dest='rootdir',\n",
    "                          default='/nas/volume1/2photon/data',\n",
    "                          help='data root dir (dir containing all animalids) [default: /nas/volume1/2photon/data, /n/coxfs01/2pdata if --slurm]')\n",
    "    parser.add_option('-i', '--animalid', action='store', dest='animalid',\n",
    "                          default='', help='Animal ID')\n",
    "\n",
    "    # Set specific session/run for current animal:\n",
    "    parser.add_option('-S', '--session', action='store', dest='session',\n",
    "                          default='', help='session dir (format: YYYMMDD_ANIMALID')\n",
    "    parser.add_option('-A', '--acq', action='store', dest='acquisition',\n",
    "                          default='FOV1', help=\"acquisition folder (ex: 'FOV1_zoom3x') [default: FOV1]\")\n",
    "    parser.add_option('-T', '--trace-type', action='store', dest='trace_type',\n",
    "                          default='raw', help=\"trace type [default: 'raw']\")\n",
    "\n",
    "    parser.add_option('-R', '--run', dest='run_list', default=[], nargs=1,\n",
    "                          action='append',\n",
    "                          help=\"run ID in order of runs\")\n",
    "    parser.add_option('-t', '--traceid', dest='traceid_list', default=[], nargs=1,\n",
    "                          action='append',\n",
    "                          help=\"trace ID in order of runs\")\n",
    "    parser.add_option('-n', '--nruns', action='store', dest='nruns', default=1, help=\"Number of consecutive runs if combined\")\n",
    "\n",
    "    parser.add_option('--slurm', action='store_true', dest='slurm', default=False, help=\"set if running as SLURM job on Odyssey\")\n",
    "    parser.add_option('--par', action='store_true', dest='multiproc', default=False, help=\"set if want to run MP on roi stats, when possible\")\n",
    "    parser.add_option('--nproc', action='store', dest='nprocesses', default=4, help=\"N processes if running in par (default=4)\")\n",
    "\n",
    "    parser.add_option('--combo', action='store_true', dest='combined', default=False, help=\"Set if using combined runs with same default name (blobs_run1, blobs_run2, etc.)\")\n",
    "\n",
    "\n",
    "    # Pupil filtering info:\n",
    "    parser.add_option('--no-pupil', action=\"store_false\",\n",
    "                      dest=\"filter_pupil\", default=True, help=\"Set flag NOT to filter PSTH traces by pupil threshold params\")\n",
    "    parser.add_option('-s', '--radius-min', action=\"store\",\n",
    "                      dest=\"pupil_radius_min\", default=25, help=\"Cut-off for smnallest pupil radius, if --pupil set [default: 25]\")\n",
    "    parser.add_option('-B', '--radius-max', action=\"store\",\n",
    "                      dest=\"pupil_radius_max\", default=65, help=\"Cut-off for biggest pupil radius, if --pupil set [default: 65]\")\n",
    "    parser.add_option('-d', '--dist', action=\"store\",\n",
    "                      dest=\"pupil_dist_thr\", default=5, help=\"Cut-off for pupil distance from start, if --pupil set [default: 5]\")\n",
    "\n",
    "    (options, args) = parser.parse_args(options)\n",
    "\n",
    "    return options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/odyssey/CE077/20180425/FOV1_zoom1x/gratings_run2/traces/traces001_0b89cd\n",
      "Loading ROIDATA file...\n",
      "[0, 45, 90, 135, 180, 225, 270, 315]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "options = ['-D', '/mnt/odyssey', '-i', 'CE077', '-S', '20180425', '-A', 'FOV1_zoom1x',\n",
    "           '-T', 'np_subtracted', '--no-pupil',\n",
    "           '-R', 'gratings_run2', '-t', 'traces001',\n",
    "           '-n', '1']\n",
    "#\n",
    "#options = ['-D', '/mnt/odyssey', '-i', 'CE077', '-S', '20180425', '-A', 'FOV1_zoom1x',\n",
    "#           '-T', 'np_subtracted', '--no-pupil',\n",
    "#           '-R', 'blobs_run1', '-t', 'traces002',\n",
    "#           '-n', '1']\n",
    "\n",
    "#options = ['-D', '/mnt/odyssey', '-i', 'CE084', '-S', '20180511', '-A', 'FOV1_zoom1x',\n",
    "#           '-T', 'np_subtracted', '--no-pupil',\n",
    "#           '-R', 'gratings_run1', '-t', 'traces002',\n",
    "#           '-n', '1']\n",
    "\n",
    "#%%\n",
    "\n",
    "options = extract_options(options)\n",
    "\n",
    "rootdir = options.rootdir\n",
    "animalid = options.animalid\n",
    "session = options.session\n",
    "acquisition = options.acquisition\n",
    "slurm = options.slurm\n",
    "if slurm is True:\n",
    "    rootdir = '/n/coxfs01/2p-data'\n",
    "\n",
    "trace_type = options.trace_type\n",
    "\n",
    "run_list = options.run_list\n",
    "traceid_list = options.traceid_list\n",
    "\n",
    "filter_pupil = options.filter_pupil\n",
    "pupil_radius_max = float(options.pupil_radius_max)\n",
    "pupil_radius_min = float(options.pupil_radius_min)\n",
    "pupil_dist_thr = float(options.pupil_dist_thr)\n",
    "pupil_max_nblinks = 0\n",
    "\n",
    "multiproc = options.multiproc\n",
    "nprocesses = int(options.nprocesses)\n",
    "combined = options.combined\n",
    "nruns = int(options.nruns)\n",
    "\n",
    "acquisition_dir = os.path.join(rootdir, animalid, session, acquisition)\n",
    "if combined is False:\n",
    "    runfolder = run_list[0]\n",
    "    traceid = traceid_list[0]\n",
    "    with open(os.path.join(acquisition_dir, runfolder, 'traces', 'traceids_%s.json' % runfolder), 'r') as f:\n",
    "        tdict = json.load(f)\n",
    "    tracefolder = '%s_%s' % (traceid, tdict[traceid]['trace_hash'])\n",
    "    traceid_dir = os.path.join(rootdir, animalid, session, acquisition, runfolder, 'traces', tracefolder)\n",
    "else:\n",
    "    assert len(run_list) == nruns, \"Incorrect runs or number of runs (%i) specified!\\n%s\" % (nruns, str(run_list))\n",
    "    runfolder = '_'.join(run_list)\n",
    "    if len(traceid_list)==1:\n",
    "        traceid = '_'.join([traceid_list[0] for i in range(nruns)])\n",
    "    traceid_dir = os.path.join(rootdir, animalid, session, acquisition, runfolder, traceid)\n",
    "\n",
    "\n",
    "print(traceid_dir)\n",
    "assert os.path.exists(traceid_dir), \"Specified traceid-dir does not exist!\"\n",
    "\n",
    "\n",
    "#%% # Load ROIDATA file:\n",
    "print \"Loading ROIDATA file...\"\n",
    "\n",
    "roidf_fn = [i for i in os.listdir(traceid_dir) if i.endswith('hdf5') and 'ROIDATA' in i and trace_type in i][0]\n",
    "roidata_filepath = os.path.join(traceid_dir, roidf_fn) #'ROIDATA_098054_626d01_raw.hdf5')\n",
    "DATA, datakey = load_roi_dataframe(roidata_filepath)\n",
    "\n",
    "transform_dict, object_transformations = vis.get_object_transforms(DATA)\n",
    "trans_types = object_transformations.keys()\n",
    "\n",
    "#%% Set filter params:\n",
    "\n",
    "if filter_pupil is True:\n",
    "    pupil_params = acq.set_pupil_params(radius_min=pupil_radius_min,\n",
    "                                        radius_max=pupil_radius_max,\n",
    "                                        dist_thr=pupil_dist_thr,\n",
    "                                        create_empty=False)\n",
    "elif filter_pupil is False:\n",
    "    pupil_params = acq.set_pupil_params(create_empty=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating OUTPUT DIRS for ROI analyses...\n",
      "Loaded 8 stimulus configurations.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#%%  Create output dir for ROI selection:\n",
    "# =============================================================================\n",
    "\n",
    "print \"Creating OUTPUT DIRS for ROI analyses...\"\n",
    "\n",
    "if '/' in datakey:\n",
    "    datakey = datakey[1:]\n",
    "sort_dir = os.path.join(traceid_dir, 'sorted_%s' % datakey)\n",
    "sort_resultsdir = os.path.join(sort_dir, 'anova_results')\n",
    "sort_figdir = os.path.join(sort_dir, 'figures')\n",
    "\n",
    "responsive_resultsdir = os.path.join(sort_dir, 'anova_results', 'responsive_tests')\n",
    "selective_resultsdir = os.path.join(sort_dir, 'anova_results', 'selectivity_tests')\n",
    "\n",
    "if not os.path.exists(sort_figdir):\n",
    "    os.makedirs(sort_figdir)\n",
    "\n",
    "if not os.path.exists(responsive_resultsdir):\n",
    "    os.makedirs(responsive_resultsdir)\n",
    "if not os.path.exists(selective_resultsdir):\n",
    "    os.makedirs(selective_resultsdir)\n",
    "\n",
    "tolerance_figdir = os.path.join(sort_dir, 'figures', 'tolerance')\n",
    "if not os.path.exists(tolerance_figdir):\n",
    "    os.makedirs(tolerance_figdir)\n",
    "\n",
    "#%% Get stimulus config info:assign_roi_selectivity\n",
    "# =============================================================================\n",
    "\n",
    "rundir = os.path.join(rootdir, animalid, session, acquisition, runfolder)\n",
    "\n",
    "if combined is True:\n",
    "    stimconfigs_fpath = os.path.join(traceid_dir, 'stimulus_configs.json')\n",
    "else:\n",
    "    stimconfigs_fpath = os.path.join(rundir, 'paradigm', 'stimulus_configs.json')\n",
    "\n",
    "with open(stimconfigs_fpath, 'r') as f:\n",
    "    stimconfigs = json.load(f)\n",
    "\n",
    "print \"Loaded %i stimulus configurations.\" % len(stimconfigs.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roi00001\n"
     ]
    }
   ],
   "source": [
    "roi_list = sorted(list(set(DATA['roi'])), key=natural_keys)\n",
    "roi = roi_list[0]\n",
    "print roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdata = DATA[DATA['roi']==roi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juliana/anaconda/envs/pipeline/lib/python2.7/site-packages/pyvttbl/stats/_anova.py:1240: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  return list(array(list(zeros((p-len(b))))+b)+1.)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdf = pyvt_raw_epochXconfig(rdata.dropna(), save_fig=False)\n",
    "# Calculate ANOVA split-plot:\n",
    "aov = pdf.anova('intensity', sub='trial',\n",
    "                   wfactors=['epoch'],\n",
    "                   bfactors=['config'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity ~ epoch * config\n",
      "\n",
      "TESTS OF BETWEEN-SUBJECTS EFFECTS\n",
      "\n",
      "Measure: intensity\n",
      "     Source          Type III     df       MS         F     Sig.    et2_G   Obs.     SE      95% CI    lambda   Obs.  \n",
      "                        SS                                                                                      Power \n",
      "=====================================================================================================================\n",
      "Between Subjects   43274744.962   79                                                                                  \n",
      "config              1767227.917    7   252461.131   0.438   0.875   0.034     10   244.202   478.636    0.426   0.064 \n",
      "=====================================================================================================================\n",
      "Error              41507517.045   72   576493.292                                                                     \n",
      "\n",
      "TESTS OF WITHIN SUBJECTS EFFECTS\n",
      "\n",
      "Measure: intensity\n",
      "    Source                             Type III      eps      df         MS         F     Sig.    et2_G   Obs.     SE      95% CI    lambda   Obs.  \n",
      "                                          SS                                                                                                  Power \n",
      "===================================================================================================================================================\n",
      "epoch            Sphericity Assumed    593398.956       -        1   593398.956   4.719   0.033   0.012     80    40.324    79.036    5.243   0.618 \n",
      "                 Greenhouse-Geisser    593398.956       1        1   593398.956   4.719   0.033   0.012     80    40.324    79.036    5.243   0.618 \n",
      "                 Huynh-Feldt           593398.956       1        1   593398.956   4.719   0.033   0.012     80    40.324    79.036    5.243   0.618 \n",
      "                 Box                   593398.956       1        1   593398.956   4.719   0.033   0.012     80    40.324    79.036    5.243   0.618 \n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch * config   Sphericity Assumed    406900.837       -        7    58128.691   0.462   0.859   0.008     10   114.055   223.547    0.449   0.065 \n",
      "                 Greenhouse-Geisser    406900.837   0.543    3.798   107134.188   0.462   0.754   0.008     10   114.055   223.547    0.449   0.061 \n",
      "                 Huynh-Feldt           406900.837   0.543    3.798   107134.188   0.462   0.754   0.008     10   114.055   223.547    0.449   0.061 \n",
      "                 Box                   406900.837   0.143        1   406900.837   0.462   0.512   0.008     10   114.055   223.547    0.449   0.056 \n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Error(epoch)     Sphericity Assumed   9054299.416       -       72   125754.159                                                                     \n",
      "                 Greenhouse-Geisser   9054299.416   0.543   39.066   231771.426                                                                     \n",
      "                 Huynh-Feldt          9054299.416   0.543   39.066   231771.426                                                                     \n",
      "                 Box                  9054299.416   0.143   10.286   880279.110                                                                     \n",
      "\n",
      "TABLES OF ESTIMATED MARGINAL MEANS\n",
      "\n",
      "Estimated Marginal Means for epoch\n",
      " epoch       Mean     Std. Error   95% Lower Bound   95% Upper Bound \n",
      "====================================================================\n",
      "baseline   1384.176       83.848          1219.834          1548.518 \n",
      "stimulus   1262.377       36.246          1191.334          1333.420 \n",
      "\n",
      "Estimated Marginal Means for config\n",
      " config       Mean     Std. Error   95% Lower Bound   95% Upper Bound \n",
      "=====================================================================\n",
      "config001   1482.048      202.915          1084.334          1879.762 \n",
      "config002   1285.653      102.370          1085.008          1486.298 \n",
      "config003   1339.536       79.590          1183.539          1495.532 \n",
      "config004   1478.013      211.538          1063.398          1892.628 \n",
      "config005   1228.027       76.285          1078.509          1377.546 \n",
      "config006   1358.145      134.467          1094.589          1621.700 \n",
      "config007   1193.533       50.314          1094.917          1292.149 \n",
      "config008   1221.257       80.748          1062.992          1379.522 \n",
      "\n",
      "Estimated Marginal Means for epoch * config\n",
      " epoch      config       Mean     Std. Error   95% Lower Bound   95% Upper Bound \n",
      "================================================================================\n",
      "baseline   config001   1620.686      380.068           875.753          2365.619 \n",
      "baseline   config002   1332.178      193.416           953.083          1711.273 \n",
      "baseline   config003   1416.133      138.606          1144.464          1687.801 \n",
      "baseline   config004   1586.022      407.724           786.883          2385.161 \n",
      "baseline   config005   1291.659      137.087          1022.969          1560.349 \n",
      "baseline   config006   1418.857      247.215           934.315          1903.400 \n",
      "baseline   config007   1149.221       73.037          1006.067          1292.374 \n",
      "baseline   config008   1258.651      144.975           974.501          1542.802 \n",
      "stimulus   config001   1343.410      158.511          1032.728          1654.091 \n",
      "stimulus   config002   1239.127       79.728          1082.860          1395.394 \n",
      "stimulus   config003   1262.939       78.934          1108.229          1417.649 \n",
      "stimulus   config004   1370.005      141.798          1092.081          1647.929 \n",
      "stimulus   config005   1164.396       69.845          1027.500          1301.291 \n",
      "stimulus   config006   1297.432      120.038          1062.158          1532.707 \n",
      "stimulus   config007   1237.845       70.128          1100.395          1375.295 \n",
      "stimulus   config008   1183.863       78.748          1029.516          1338.209 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    print(aov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline",
   "language": "python",
   "name": "pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
