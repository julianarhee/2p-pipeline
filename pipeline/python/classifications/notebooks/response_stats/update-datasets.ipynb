{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/coxfs01/2p-pipeline/envs/pipeline/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json \n",
    "\n",
    "import numpy as np\n",
    "import cPickle as pkl\n",
    "\n",
    "import seaborn as sns\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "\n",
    "from pipeline.python.utils import natural_keys\n",
    "from pipeline.python.classifications import experiment_classes as util\n",
    "import cPickle as pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_animalids(fov_type='zoom2px'):\n",
    "    \n",
    "    all_paths = glob.glob(os.path.join(rootdir, 'JC*', '20*', '*zoom2p0x*')) #sessionmeta.json'))\n",
    "    included_paths = [p for p in all_paths if int(p.split(rootdir)[1].split('/')[2]) >= 20190301] #20190406]\n",
    "    animalids = sorted(list(set([p.split(rootdir)[1].split('/')[1] for p in included_paths])), key=natural_keys)\n",
    "    print(\"Found %i animals with FOV: %s\" %(len(animalids),  fov_type))\n",
    "    \n",
    "    return animalids\n",
    "\n",
    "class MetaData():\n",
    "    def __init__(self, animalid, rootdir='/n/coxfs01/2p-data'):\n",
    "        self.animalid = animalid\n",
    "        self.anesthetized_session_list = []\n",
    "        self.sessions = {}\n",
    "    \n",
    "    def update_sessions(self, fov_type='zoom2p0x'):\n",
    "        blacklist = ['JC097_20190717_FOV1', \n",
    "                     'JC089_20190523_FOV1', 'JC089_20190523_FOV2',\n",
    "                     'JC092_20190527_FOV1']\n",
    "        # Check if anesthetized info / visual area info stored in metafile:\n",
    "        meta_info_file = os.path.join(rootdir, self.animalid, 'sessionmeta.json')\n",
    "        meta_info = {}\n",
    "        if os.path.exists(meta_info_file):\n",
    "            try:\n",
    "                with open(meta_info_file, 'r') as f:\n",
    "                    meta_info = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(\"...creating new meta file\")\n",
    "                \n",
    "        # Get all session for current animal:\n",
    "        session_paths =  sorted(glob.glob(os.path.join(rootdir, self.animalid,  '*', 'FOV*_%s' % fov_type)), key=natural_keys)\n",
    "\n",
    "        print(\"Found %i acquisitions.\" % len(session_paths))\n",
    "        for si, session_path in enumerate(session_paths):\n",
    "            session_name = os.path.split(session_path.split('/FOV')[0])[-1]\n",
    "            fov_name = os.path.split(session_path)[-1]\n",
    "            print(\"[%s]: %s - %s\" % (animalid, session_name, fov_name))\n",
    "            skey = '%s_%s' % (session_name, fov_name.split('_')[0])\n",
    "            if '%s_%s' % (self.animalid, skey) in blacklist:\n",
    "                print(\"... excluded dataset, skipping\")\n",
    "                continue\n",
    "\n",
    "            # Update meta info if this is a new session:\n",
    "            if skey not in meta_info.keys():\n",
    "                user_input = raw_input('--> (%s)\\n--  Was this session anesthetized? [Y/n]' % skey)\n",
    "                if user_input == 'Y':\n",
    "                    #self.anesthetized_session_list.append(session_name)\n",
    "                    state = 'anesthetized'\n",
    "                else:\n",
    "                    state = 'awake'\n",
    "                visual_area = raw_input('--  Enter visual area recorded: ')\n",
    "                meta_info.update({skey: {'state': state,\n",
    "                                        'visual_area': visual_area}})\n",
    "            else:\n",
    "                state = meta_info[skey]['state']\n",
    "                visual_area = meta_info[skey]['visual_area']\n",
    "                \n",
    "            with open(meta_info_file, 'w') as f:\n",
    "                json.dump(meta_info, f, sort_keys=True, indent=4)\n",
    "        return meta_info\n",
    "    \n",
    "            \n",
    "    def get_sessions(self, fov_type='zoom2p0x', session_list = [],\n",
    "                     create_new=False, rootdir='/n/coxfs01/2p-data'):\n",
    "\n",
    "        # Check if anesthetized info / visual area info stored in metafile:\n",
    "        create_meta = False\n",
    "        meta_info_file = os.path.join(rootdir, animalid, 'sessionmeta.json')\n",
    "        if os.path.exists(meta_info_file):\n",
    "            try:\n",
    "                with open(meta_info_file, 'r') as f:\n",
    "                    meta_info = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(\"...creating new meta file\")\n",
    "                create_meta = True\n",
    "        else:\n",
    "            create_new = True\n",
    "            create_meta = True\n",
    "            \n",
    "        if create_meta:\n",
    "            meta_info = {}\n",
    "        \n",
    "        # Get all session for current animal:\n",
    "        if len(session_list) == 0:\n",
    "            session_paths =  sorted(glob.glob(os.path.join(rootdir, animalid, '*', 'FOV*_%s' % fov_type)), key=natural_keys)\n",
    "        else:\n",
    "            session_paths = sorted([glob.glob(os.path.join(rootdir, animalid,  '%s' % s.split('_')[0], \n",
    "                                                           '%s_%s' % (s.split('_')[1], fov_type)))[0]\\\n",
    "                                   for s in session_list], key=natural_keys)\n",
    "        print(\"Found %i acquisitions.\" % len(session_paths))\n",
    "        for si, session_path in enumerate(session_paths):\n",
    "            session_name = os.path.split(session_path.split('/FOV')[0])[-1]\n",
    "            fov_name = os.path.split(session_path)[-1]\n",
    "            print(\"[%s]: %s - %s\" % (animalid, session_name, fov_name))\n",
    "            skey = '%s_%s' % (session_name, fov_name.split('_')[0])\n",
    "\n",
    "            # Load session data, if exists:\n",
    "            output_dir = os.path.join(rootdir, animalid, session_name, fov_name, 'summaries')\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            session_outfile = os.path.join(output_dir, 'sessiondata.pkl')                \n",
    "            \n",
    "            if not create_new:\n",
    "                try:\n",
    "                    assert os.path.exists(session_outfile), \"... session object does not exist, creating new.\"\n",
    "                    print(\"... loading session object...\") #% (animalid, session_name))\n",
    "                    with open(session_outfile, 'rb') as f:\n",
    "                        S = pkl.load(f)\n",
    "                        assert 'visual_area' in dir(S), \"... No visual area found, creating new.\"\n",
    "                except Exception as e:\n",
    "                    print e\n",
    "                    create_new = True\n",
    "            \n",
    "            # Update meta info if this is a new session:\n",
    "            if skey not in meta_info.keys():\n",
    "                user_input = raw_input('Was this session anesthetized? [Y/n]')\n",
    "                if user_input == 'Y':\n",
    "                    #self.anesthetized_session_list.append(session_name)\n",
    "                    state = 'anesthetized'\n",
    "                else:\n",
    "                    state = 'awake'\n",
    "                visual_area = raw_input('Enter visual area recorded: ')\n",
    "                meta_info.update({skey: {'state': state,\n",
    "                                        'visual_area': visual_area}})\n",
    "            else:\n",
    "                state = meta_info[skey]['state']\n",
    "                visual_area = meta_info[skey]['visual_area']\n",
    "                \n",
    "\n",
    "            if create_new:\n",
    "                print(\"Creating new session object...\") #% (animalid, session_name))\n",
    "                S = util.Session(animalid, session_name, fov_name, \n",
    "                                 visual_area=visual_area, state=state,\n",
    "                                 rootdir=rootdir)\n",
    "                #S.load_data(traceid=traceid, trace_type='corrected')\n",
    "                # Save session data object\n",
    "                with open(session_outfile, 'wb') as f:\n",
    "                    pkl.dump(S, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "                \n",
    "            self.sessions[skey] = S\n",
    "            \n",
    "            if state == 'anesthetized' and skey not in self.anesthetized_session_list:\n",
    "                self.anesthetized_session_list.append(skey)\n",
    "                \n",
    "            with open(meta_info_file, 'w') as f:\n",
    "                json.dump(meta_info, f, sort_keys=True, indent=4)\n",
    "        return self.sessions\n",
    "    \n",
    "            \n",
    "    def load_experiments(self, experiment=None, select_subset=False,\n",
    "                         state=None, visual_area=None,\n",
    "                         traceid='traces001', trace_type='corrected', load_raw=False,\n",
    "                         responsive_thr=0.01, responsive_test='ROC',\n",
    "                         receptive_field_fit='zscore0.00_no_trim',\n",
    "                         update=True, get_grouped=True,\n",
    "                         rootdir='/n/coxfs01/2p-data'):\n",
    "        \n",
    "        # Make sure output dir exists:\n",
    "        if not os.path.exists(os.path.join(rootdir, 'summary_stats', 'animals')):\n",
    "            os.makedirs(os.path.join(rootdir, 'summary_stats', 'animals'))\n",
    "            \n",
    "        #session_stats = {}\n",
    "        assert len(self.sessions.keys()) > 0, \"** no sessions found! **\"\n",
    "        for skey, sobj in self.sessions.items():\n",
    "            \n",
    "            if select_subset:\n",
    "                # Select subset of sessions, based on visual area or state:\n",
    "                if state == 'awake' and skey in self.anesthetized_session_list:\n",
    "                    continue\n",
    "                if state == 'anesthetized' and skey not in self.anesthetized_session_list:\n",
    "                    continue\n",
    "                if visual_area is not None and sobj.visual_area != visual_area:\n",
    "                    continue\n",
    "            \n",
    "            # Do correction on experiment names for sessions before 20190511\n",
    "            if experiment == 'rfs' and int(sobj.session) < 20190511:\n",
    "                experiment_name = 'gratings'\n",
    "            elif experiment == 'gratings' and int(sobj.session) < 20190511: \n",
    "                continue\n",
    "            elif experiment == 'blobs' and sobj.animalid == 'JC078' and sobj.session == '20190426':\n",
    "                continue\n",
    "            else:\n",
    "                experiment_name = experiment\n",
    "            \n",
    "            # Either load traces/labels or summary stats:\n",
    "            if load_raw:\n",
    "                if sobj.data.traces is None:\n",
    "                    expdict = sobj.load_data(experiment=experiment_name, traceid=traceid, trace_type=trace_type)\n",
    "                else:\n",
    "                    expdict = sobj.experiments[experiment_name]\n",
    "            else:\n",
    "                expdict = sobj.get_grouped_stats(experiment_type=experiment_name,\n",
    "                                  traceid=traceid, trace_type=trace_type, \n",
    "                                  responsive_test=responsive_test, responsive_thr=responsive_thr,\n",
    "                                  receptive_field_fit=receptive_field_fit,\n",
    "                                  update=update, get_grouped=get_grouped,\n",
    "                                  rootdir=rootdir)\n",
    "        \n",
    "            #if expdict is not None:\n",
    "            #    session_stats[skey] = expdict\n",
    "            if expdict is not None:\n",
    "                outfile = os.path.join(rootdir, 'summary_stats', 'animals', '%s_%s.pkl' % (self.animalid, skey))\n",
    "                with open(outfile, 'wb') as f:\n",
    "                    pkl.dump(expdict, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "                print(\"... saved session states: %s\" % outfile)\n",
    "            if update:\n",
    "                # Load session data, if exists:\n",
    "                sobj.save_session(rootdir=rootdir)\n",
    "                print(\"... updated session object: %s\" % skey)\n",
    "                    \n",
    "        return #session_stats\n",
    "            \n",
    "    \n",
    "    def save_session_stats(self, outfile=None, rootdir='/n/coxfs01/2p-data'):\n",
    "        #if outfile is None:\n",
    "        #    outfile = os.path.join(rootdir, '%s.pkl' % self.animalid)\n",
    "        \n",
    "        #with open(outfile, 'wb') as f:\n",
    "        #    pkl.dump(self, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        for skey, sobj in self.sessions.items():\n",
    "            curr_outfile = os.path.join(rootdir, '%s_%s.pkl' % (self.animalid, skey))\n",
    "            with open(curr_outfile, 'wb') as f:\n",
    "                pkl.dump(sobj, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        print(\"--- saved animal data to:\\n%s\" % outfile)\n",
    "                     \n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootdir = '/n/coxfs01/2p-data'\n",
    "traceid = 'traces001'\n",
    "\n",
    "animalids = ['JC067', 'JC070', 'JC073',\n",
    "             'JC076', 'JC078', 'JC080', 'JC083', 'JC084', \n",
    "             'JC085', 'JC090', 'JC091', 'JC097', 'JC099', \n",
    "             'JC110', 'JC111', 'JC113', 'JC117', 'JC120']\n",
    "\n",
    "\n",
    "fov_type = 'zoom2p0x'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 animals with FOV: zoom2p0x\n",
      "Found 2 acquisitions.\n",
      "[JC061]: 20190306 - FOV2_zoom2p0x\n",
      "[JC061]: 20190306 - FOV3_zoom2p0x\n",
      "Found 2 acquisitions.\n",
      "[JC067]: 20190319 - FOV1_zoom2p0x\n",
      "[JC067]: 20190320 - FOV1_zoom2p0x\n",
      "Found 8 acquisitions.\n",
      "[JC070]: 20190314 - FOV1_zoom2p0x\n",
      "[JC070]: 20190314 - FOV2_zoom2p0x\n",
      "[JC070]: 20190315 - FOV1_zoom2p0x\n",
      "[JC070]: 20190315 - FOV2_zoom2p0x\n",
      "[JC070]: 20190315 - FOV3_zoom2p0x\n",
      "[JC070]: 20190316 - FOV1_zoom2p0x\n",
      "[JC070]: 20190321 - FOV1_zoom2p0x\n",
      "[JC070]: 20190321 - FOV2_zoom2p0x\n",
      "Found 3 acquisitions.\n",
      "[JC073]: 20190321 - FOV1_zoom2p0x\n",
      "[JC073]: 20190322 - FOV1_zoom2p0x\n",
      "[JC073]: 20190327 - FOV1_zoom2p0x\n",
      "Found 14 acquisitions.\n",
      "[JC076]: 20190405 - FOV1_zoom2p0x\n",
      "[JC076]: 20190405 - FOV2_zoom2p0x\n",
      "[JC076]: 20190406 - FOV1_zoom2p0x\n",
      "[JC076]: 20190408 - FOV1_zoom2p0x\n",
      "[JC076]: 20190410 - FOV1_zoom2p0x\n",
      "[JC076]: 20190419 - FOV1_zoom2p0x\n",
      "[JC076]: 20190420 - FOV1_zoom2p0x\n",
      "[JC076]: 20190422 - FOV1_zoom2p0x\n",
      "[JC076]: 20190423 - FOV1_zoom2p0x\n",
      "[JC076]: 20190424 - FOV1_zoom2p0x\n",
      "[JC076]: 20190427 - FOV1_zoom2p0x\n",
      "[JC076]: 20190501 - FOV1_zoom2p0x\n",
      "[JC076]: 20190502 - FOV1_zoom2p0x\n",
      "[JC076]: 20190503 - FOV1_zoom2p0x\n",
      "Found 7 acquisitions.\n",
      "[JC078]: 20190424 - FOV1_zoom2p0x\n",
      "[JC078]: 20190426 - FOV1_zoom2p0x\n",
      "[JC078]: 20190427 - FOV1_zoom2p0x\n",
      "[JC078]: 20190430 - FOV1_zoom2p0x\n",
      "[JC078]: 20190504 - FOV1_zoom2p0x\n",
      "[JC078]: 20190509 - FOV1_zoom2p0x\n",
      "[JC078]: 20190513 - FOV1_zoom2p0x\n",
      "Found 7 acquisitions.\n",
      "[JC080]: 20190430 - FOV1_zoom2p0x\n",
      "[JC080]: 20190506 - FOV1_zoom2p0x\n",
      "[JC080]: 20190514 - FOV1_zoom2p0x\n",
      "[JC080]: 20190530 - FOV1_zoom2p0x\n",
      "[JC080]: 20190602 - FOV1_zoom2p0x\n",
      "[JC080]: 20190602 - FOV2_zoom2p0x\n",
      "[JC080]: 20190603 - FOV1_zoom2p0x\n",
      "Found 8 acquisitions.\n",
      "[JC083]: 20190505 - FOV1_zoom2p0x\n",
      "[JC083]: 20190505 - FOV2_zoom2p0x\n",
      "[JC083]: 20190507 - FOV1_zoom2p0x\n",
      "[JC083]: 20190508 - FOV1_zoom2p0x\n",
      "[JC083]: 20190510 - FOV1_zoom2p0x\n",
      "[JC083]: 20190511 - FOV1_zoom2p0x\n",
      "[JC083]: 20190512 - FOV1_zoom2p0x\n",
      "[JC083]: 20190517 - FOV1_zoom2p0x\n",
      "Found 5 acquisitions.\n",
      "[JC084]: 20190518 - FOV1_zoom2p0x\n",
      "[JC084]: 20190518 - FOV2_zoom2p0x\n",
      "[JC084]: 20190522 - FOV1_zoom2p0x\n",
      "[JC084]: 20190523 - FOV1_zoom2p0x\n",
      "[JC084]: 20190525 - FOV1_zoom2p0x\n",
      "Found 4 acquisitions.\n",
      "[JC085]: 20190620 - FOV1_zoom2p0x\n",
      "[JC085]: 20190620 - FOV2_zoom2p0x\n",
      "[JC085]: 20190620 - FOV3_zoom2p0x\n",
      "[JC085]: 20190622 - FOV1_zoom2p0x\n",
      "Found 2 acquisitions.\n",
      "[JC086]: 20190515 - FOV1_zoom2p0x\n",
      "[JC086]: 20190515 - FOV2_zoom2p0x\n",
      "Found 5 acquisitions.\n",
      "[JC089]: 20190519 - FOV1_zoom2p0x\n",
      "[JC089]: 20190520 - FOV1_zoom2p0x\n",
      "[JC089]: 20190522 - FOV1_zoom2p0x\n",
      "[JC089]: 20190523 - FOV1_zoom2p0x\n",
      "... excluded dataset, skipping\n",
      "[JC089]: 20190523 - FOV2_zoom2p0x\n",
      "... excluded dataset, skipping\n",
      "Found 4 acquisitions.\n",
      "[JC090]: 20190604 - FOV1_zoom2p0x\n",
      "[JC090]: 20190604 - FOV2_zoom2p0x\n",
      "[JC090]: 20190604 - FOV3_zoom2p0x\n",
      "[JC090]: 20190605 - FOV1_zoom2p0x\n",
      "Found 8 acquisitions.\n",
      "[JC091]: 20190601 - FOV1_zoom2p0x\n",
      "[JC091]: 20190602 - FOV1_zoom2p0x\n",
      "[JC091]: 20190606 - FOV1_zoom2p0x\n",
      "[JC091]: 20190607 - FOV1_zoom2p0x\n",
      "[JC091]: 20190614 - FOV1_zoom2p0x\n",
      "[JC091]: 20190627 - FOV1_zoom2p0x\n",
      "[JC091]: 20191007 - FOV1_zoom2p0x\n",
      "[JC091]: 20191008 - FOV1_zoom2p0x\n",
      "Found 5 acquisitions.\n",
      "[JC092]: 20190526 - FOV1_zoom2p0x\n",
      "[JC092]: 20190527 - FOV1_zoom2p0x\n",
      "... excluded dataset, skipping\n",
      "[JC092]: 20190527 - FOV2_zoom2p0x\n",
      "[JC092]: 20190527 - FOV3_zoom2p0x\n",
      "[JC092]: 20190528 - FOV1_zoom2p0x\n",
      "Found 9 acquisitions.\n",
      "[JC097]: 20190610 - FOV1_zoom2p0x\n",
      "[JC097]: 20190613 - FOV1_zoom2p0x\n",
      "[JC097]: 20190615 - FOV1_zoom2p0x\n",
      "[JC097]: 20190615 - FOV2_zoom2p0x\n",
      "[JC097]: 20190615 - FOV3_zoom2p0x\n",
      "[JC097]: 20190616 - FOV1_zoom2p0x\n",
      "[JC097]: 20190617 - FOV1_zoom2p0x\n",
      "[JC097]: 20190618 - FOV1_zoom2p0x\n",
      "[JC097]: 20190717 - FOV1_zoom2p0x\n",
      "... excluded dataset, skipping\n",
      "Found 7 acquisitions.\n",
      "[JC099]: 20190608 - FOV1_zoom2p0x\n",
      "[JC099]: 20190608 - FOV2_zoom2p0x\n",
      "[JC099]: 20190608 - FOV3_zoom2p0x\n",
      "[JC099]: 20190608 - FOV3a_zoom2p0x\n",
      "[JC099]: 20190609 - FOV1_zoom2p0x\n",
      "[JC099]: 20190612 - FOV1_zoom2p0x\n",
      "[JC099]: 20190617 - FOV1_zoom2p0x\n",
      "Found 1 acquisitions.\n",
      "[JC101]: 20190620 - FOV1_zoom2p0x\n",
      "Found 5 acquisitions.\n",
      "[JC110]: 20191004 - FOV1_zoom2p0x\n",
      "[JC110]: 20191004 - FOV2_zoom2p0x\n",
      "[JC110]: 20191004 - FOV3_zoom2p0x\n",
      "[JC110]: 20191004 - FOV4_zoom2p0x\n",
      "[JC110]: 20191006 - FOV1_zoom2p0x\n",
      "Found 1 acquisitions.\n",
      "[JC111]: 20191003 - FOV1_zoom2p0x\n",
      "Found 7 acquisitions.\n",
      "[JC113]: 20191012 - FOV1_zoom2p0x\n",
      "[JC113]: 20191012 - FOV2_zoom2p0x\n",
      "[JC113]: 20191012 - FOV3_zoom2p0x\n",
      "[JC113]: 20191017 - FOV1_zoom2p0x\n",
      "[JC113]: 20191018 - FOV1_zoom2p0x\n",
      "[JC113]: 20191108 - FOV1_zoom2p0x\n",
      "[JC113]: 20191108 - FOV2_zoom2p0x\n",
      "Found 5 acquisitions.\n",
      "[JC117]: 20191104 - FOV1_zoom2p0x\n",
      "[JC117]: 20191104 - FOV2_zoom2p0x\n",
      "[JC117]: 20191105 - FOV1_zoom2p0x\n",
      "[JC117]: 20191111 - FOV1_zoom2p0x\n",
      "[JC117]: 20191111 - FOV2_zoom2p0x\n",
      "Found 5 acquisitions.\n",
      "[JC120]: 20191105 - FOV1_zoom2p0x\n",
      "[JC120]: 20191106 - FOV1_zoom2p0x\n",
      "[JC120]: 20191106 - FOV3_zoom2p0x\n",
      "[JC120]: 20191106 - FOV4_zoom2p0x\n",
      "[JC120]: 20191111 - FOV1_zoom2p0x\n"
     ]
    }
   ],
   "source": [
    "\n",
    "animalids = get_animalids(fov_type=fov_type)\n",
    "\n",
    "for animalid in animalids:\n",
    "    A = MetaData(animalid)\n",
    "    slist = A.update_sessions(fov_type=fov_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9766a4ea5d66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gd' is not defined"
     ]
    }
   ],
   "source": [
    "reload(util)\n",
    "reload(gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "[JC084] Li - skipping\n",
      "[JC111] V1 - skipping\n",
      "[JC111] Lm - skipping\n",
      "Creating new session object...\n",
      "[JC091] V1 - skipping\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "... no anat\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "[JC085] Lm - skipping\n",
      "[JC085] Li - skipping\n",
      "[JC089] V1 - skipping\n",
      "[JC089] Lm - skipping\n",
      "Creating new session object...\n",
      "[JC090] V1 - skipping\n",
      "[JC090] Lm - skipping\n",
      "Creating new session object...\n",
      "[JC099] V1 - skipping\n",
      "[JC099] Lm - skipping\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "[JC101] V1 - skipping\n",
      "[JC101] Lm - skipping\n",
      "[JC101] Li - skipping\n",
      "[JC092] V1 - skipping\n",
      "[JC092] Lm - skipping\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "[JC097] Li - skipping\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "[JC110] Li - skipping\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "... no anat\n",
      "Creating new session object...\n",
      "... no anat\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "[JC061] V1 - skipping\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "[JC061] Li - skipping\n",
      "[JC070] V1 - skipping\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "... no anat\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "... no anat\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "[JC067] V1 - skipping\n",
      "[JC067] Lm - skipping\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "[JC073] V1 - skipping\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "[JC073] Li - skipping\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "[JC078] V1 - skipping\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "... no anat\n",
      "[JC078] Li - skipping\n",
      "[JC080] V1 - skipping\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "... no anat\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "... no anat\n",
      "Creating new session object...\n",
      "... no anat\n",
      "Creating new session object...\n",
      "... no anat\n",
      "[JC083] Li - skipping\n",
      "[JC086] V1 - skipping\n",
      "[JC086] Lm - skipping\n",
      "[JC086] Li - skipping\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n",
      "Creating new session object...\n"
     ]
    }
   ],
   "source": [
    "from pipeline.python.classifications import get_dataset_stats as gd\n",
    "options = ['-t', 'traces001', '-F', fov_type]\n",
    "optsE = gd.extract_options(options)\n",
    "sdata_fpath = os.path.join(optsE.aggregate_dir, 'dataset_info.pkl')\n",
    "\n",
    "sdata = gd.aggregate_session_info(traceid=optsE.traceid, trace_type=optsE.trace_type, \n",
    "                                   state=optsE.state, fov_type=optsE.fov_type, \n",
    "                                   visual_areas=optsE.visual_areas,\n",
    "                                   #blacklist=optsE.blacklist, \n",
    "                                   rootdir=optsE.rootdir)\n",
    "\n",
    "with open(sdata_fpath, 'wb') as f:\n",
    "    pkl.dump(sdata, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "        \n",
    "#%%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata[sdata['experiment']!='blobs_pos'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_animals = ['JC061', 'JC067', 'JC070', 'JC073']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sdata[sdata['experiment']!='blobs_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(sdata_fpath, 'wb') as f:\n",
    "    pkl.dump(sdata, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241, 7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
